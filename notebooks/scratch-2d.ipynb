{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68855ba8-431c-42e7-84c1-3613d4a98883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import stheno\n",
    "from stheno import GP, EQ\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from cnp.experiment import (\n",
    "    generate_root,\n",
    "    WorkingDirectory,\n",
    "    save_checkpoint,\n",
    "    log_args\n",
    ")\n",
    "\n",
    "from cnp.cnp import (\n",
    "    StandardGNP,\n",
    "    StandardAGNP,\n",
    "    StandardConvGNP,\n",
    "    FullConvGNP\n",
    ")\n",
    "\n",
    "from cnp.lnp import (\n",
    "    StandardANP,\n",
    "    StandardConvNP,\n",
    "    StandardHalfUNetConvNP\n",
    ")\n",
    "\n",
    "from cnp.cov import (\n",
    "    InnerProdCov,\n",
    "    KvvCov,\n",
    "    MeanFieldCov,\n",
    "    AddHomoNoise,\n",
    "    AddHeteroNoise,\n",
    "    AddNoNoise\n",
    ")\n",
    "\n",
    "from cnp.oracle import (\n",
    "    eq_cov,\n",
    "    mat_cov,\n",
    "    nm_cov,\n",
    "    wp_cov,\n",
    "    gp_loglik\n",
    ")\n",
    "\n",
    "from cnp.utils import (\n",
    "    plot_samples_and_data,\n",
    "    make_generator,\n",
    "    Logger\n",
    ")\n",
    "\n",
    "import torch\n",
    "from torch.distributions import MultivariateNormal\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03408d36-4cc7-4cfd-b6df-6d45137f6e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_loglik(xc, yc, xt, yt, covariance, noise=0.05**2):\n",
    "    \n",
    "    p = GP(covariance)\n",
    "    p_post = p | (p(xc, noise), yc)\n",
    "    pred = p_post(xt, noise)\n",
    "    \n",
    "    loglik = pred.logpdf(yt)\n",
    "    \n",
    "    return loglik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f4377c0-3852-40f2-810a-3c3bdf706974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Training epoch helper\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def train(data,\n",
    "          model,\n",
    "          optimiser,\n",
    "          log_every,\n",
    "          device,\n",
    "          writer,\n",
    "          iteration):\n",
    "    \n",
    "    for step, batch in enumerate(data):\n",
    "\n",
    "        nll = model.loss(batch['x_context'].to(device),\n",
    "                         batch['y_context'].to(device),\n",
    "                         batch['x_target'].to(device),\n",
    "                         batch['y_target'].to(device))\n",
    "\n",
    "        if step % log_every == 0:\n",
    "            print(f\"Training   neg. log-lik: {nll:.2f}\")\n",
    "\n",
    "        # Compute gradients and apply them\n",
    "        nll.backward()\n",
    "        optimiser.step()\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # Write to tensorboard\n",
    "        writer.add_scalar('Train log-lik.', - nll, iteration)\n",
    "        \n",
    "        iteration = iteration + 1\n",
    "        \n",
    "    return iteration\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Validation helper\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def validate(data,\n",
    "             oracle_cov,\n",
    "             model,\n",
    "             args_np_val_samples,\n",
    "             device,\n",
    "             writer,\n",
    "             latent_model):\n",
    "    \n",
    "    # Lists for logging model's training NLL and oracle NLL\n",
    "    nll_list = []\n",
    "    oracle_nll_list = []\n",
    "    \n",
    "    # If training a latent model, set the number of latent samples accordingly\n",
    "    loss_kwargs = {'num_samples' : args_np_val_samples} if latent_model else {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for step, batch in enumerate(data):\n",
    "            \n",
    "            nll = model.loss(batch['x_context'].to(device),\n",
    "                             batch['y_context'].to(device),\n",
    "                             batch['x_target'].to(device),\n",
    "                             batch['y_target'].to(device),\n",
    "                             **loss_kwargs)\n",
    "            \n",
    "            oracle_nll = torch.tensor(0.)\n",
    "\n",
    "            # Oracle loss exists only for GP-generated data, not sawtooth\n",
    "            if oracle_cov is not None:\n",
    "                for b in range(batch['x_context'].shape[0]):\n",
    "                    oracle_nll = oracle_nll - gp_loglik(batch['x_context'][b].detach().cpu().numpy(),\n",
    "                                                        batch['y_context'][b].detach().cpu().numpy(),\n",
    "                                                        batch['x_target'][b].detach().cpu().numpy(),\n",
    "                                                        batch['y_target'][b].detach().cpu().numpy(),\n",
    "                                                        oracle_cov)\n",
    "                        \n",
    "\n",
    "            # Scale by the average number of target points\n",
    "            nll_list.append(nll.item())\n",
    "            oracle_nll_list.append(oracle_nll.item() / batch['x_context'].shape[0])\n",
    "\n",
    "    mean_nll = np.mean(nll_list)\n",
    "    std_nll = np.var(nll_list)**0.5\n",
    "    \n",
    "    mean_oracle_nll = np.mean(oracle_nll_list)\n",
    "    std_oracle_nll = np.var(oracle_nll_list)**0.5\n",
    "\n",
    "    # Print validation loss and oracle loss\n",
    "    print(f\"Validation neg. log-lik: \"\n",
    "          f\"{mean_nll:.2f}\")\n",
    "\n",
    "    print(f\"Oracle     neg. log-lik: \"\n",
    "          f\"{mean_oracle_nll:.2f}\")\n",
    "\n",
    "    return mean_nll, std_nll, mean_oracle_nll, std_oracle_nll\n",
    "\n",
    "args_data = 'eq'\n",
    "args_x_dim = 2\n",
    "args_batch_size = 4\n",
    "args_max_num_context = 50\n",
    "args_min_num_target = 100\n",
    "args_max_num_target = 100\n",
    "args_seed = 0\n",
    "args_validate_every = 10\n",
    "args_model = 'convNP'\n",
    "args_covtype = 'meanfield'\n",
    "args_np_loss_samples = 10\n",
    "args_np_val_samples = 10\n",
    "args_num_basis_dim = 512\n",
    "args_learning_rate = 5e-4\n",
    "args_weight_decay = 0.\n",
    "args_num_params = False\n",
    "args_gpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d99c3d2-c8b0-49d9-9df9-b1ca4cf355a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root: ../experiments/synthetic/results/eq/models/convNP/meanfield/seed-0/dim-2\n",
      "Root: ../experiments/synthetic/toy-data/eq-2-4-50-100-100-0\n",
      "Root: ../experiments/synthetic/logs\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Set random seed, device and tensorboard writer\n",
    "# =============================================================================\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(args_seed)\n",
    "torch.manual_seed(args_seed)\n",
    "\n",
    "# Set device\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(args_gpu)\n",
    "    \n",
    "use_cpu = not torch.cuda.is_available() and args_gpu == 0\n",
    "device = torch.device('cpu') if use_cpu else torch.device('cuda')\n",
    "\n",
    "root = '../experiments/synthetic'\n",
    "\n",
    "# Working directory for saving results\n",
    "experiment_name = os.path.join(f'{root}',\n",
    "                               f'results',\n",
    "                               f'{args_data}',\n",
    "                               f'models',\n",
    "                               f'{args_model}',\n",
    "                               f'{args_covtype}',\n",
    "                               f'seed-{args_seed}',\n",
    "                               f'dim-{args_x_dim}')\n",
    "working_directory = WorkingDirectory(root=experiment_name)\n",
    "\n",
    "# Data directory for loading data\n",
    "suffix = f'{args_x_dim}-'           + \\\n",
    "         f'{args_batch_size}-'      + \\\n",
    "         f'{args_max_num_context}-' + \\\n",
    "         f'{args_min_num_target}-'  + \\\n",
    "         f'{args_max_num_target}-'  + \\\n",
    "         f'{args_seed}'\n",
    "\n",
    "data_root = os.path.join(root, 'toy-data', f'{args_data}-{suffix}')\n",
    "data_directory = WorkingDirectory(root=data_root)\n",
    "\n",
    "log_path = f'{root}/logs'\n",
    "log_filename = f'{args_data}-{args_model}-{args_covtype}-{args_seed}'\n",
    "log_directory = WorkingDirectory(root=log_path)\n",
    "# sys.stdout = Logger(log_directory=log_directory, log_filename=log_filename)\n",
    "\n",
    "# Tensorboard writer\n",
    "writer = SummaryWriter(f'{experiment_name}/log')\n",
    "    \n",
    "file = open(working_directory.file('data_location.txt'), 'w')\n",
    "file.write(data_directory.root)\n",
    "file.close()\n",
    "\n",
    "# =============================================================================\n",
    "# Load data and validation oracle generator\n",
    "# =============================================================================\n",
    "    \n",
    "file = open(data_directory.file('train-data.pkl'), 'rb')\n",
    "data_train = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open(data_directory.file('valid-data.pkl'), 'rb')\n",
    "data_val = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "oracle_cov = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd87ee26-a9ff-4d2a-abcb-9b1e77bda615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "from cnp.encoders import (\n",
    "    StandardEncoder,\n",
    "    ConvEncoder,\n",
    "    StandardANPEncoder,\n",
    "    StandardConvNPEncoder\n",
    ")\n",
    "\n",
    "from cnp.decoders import (\n",
    "    StandardDecoder,\n",
    "    ConvDecoder\n",
    ")\n",
    "\n",
    "from cnp.architectures import (\n",
    "    UNet,\n",
    "    HalfUNet,\n",
    "    StandardDepthwiseSeparableCNN\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361d71ee-ae1e-40bb-b8d4-1f5772960d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convNP meanfield 512: 503415\n",
      "\n",
      "Epoch: 1/101\n",
      "Validation neg. log-lik: 381.38\n",
      "Oracle     neg. log-lik: -109.75\n",
      "Training   neg. log-lik: 382.25\n",
      "Training   neg. log-lik: 104.07\n",
      "Training   neg. log-lik: 81.04\n",
      "Training   neg. log-lik: 65.14\n",
      "Training   neg. log-lik: 51.86\n",
      "Training   neg. log-lik: 47.87\n",
      "Training   neg. log-lik: 77.57\n",
      "Training   neg. log-lik: 41.30\n",
      "Training   neg. log-lik: 20.99\n",
      "\n",
      "Epoch: 2/101\n",
      "Training   neg. log-lik: 18.13\n",
      "Training   neg. log-lik: 4.63\n",
      "Training   neg. log-lik: 60.51\n",
      "Training   neg. log-lik: 35.91\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Create model\n",
    "# =============================================================================\n",
    "\n",
    "# Create covariance method\n",
    "if args_covtype == 'meanfield':\n",
    "    cov = MeanFieldCov(num_basis_dim=1)\n",
    "    noise = AddNoNoise()\n",
    "\n",
    "elif args_covtype == 'innerprod-homo':\n",
    "    cov = InnerProdCov(args_num_basis_dim)\n",
    "    noise = AddHomoNoise()\n",
    "    \n",
    "elif args_covtype == 'kvv-homo':\n",
    "    cov = KvvCov(args_num_basis_dim)\n",
    "    noise = AddHomoNoise()\n",
    "    \n",
    "# Create model architecture\n",
    "\n",
    "if args_model == 'GNP':\n",
    "    model = StandardGNP(input_dim=args_x_dim,\n",
    "                        covariance=cov,\n",
    "                        add_noise=noise)\n",
    "\n",
    "elif args_model == 'AGNP':\n",
    "    model = StandardAGNP(input_dim=args_x_dim,\n",
    "                         covariance=cov,\n",
    "                         add_noise=noise)\n",
    "\n",
    "elif args_model == 'convGNP':\n",
    "    model = StandardConvGNP(input_dim=args_x_dim,\n",
    "                            covariance=cov,\n",
    "                            add_noise=noise)\n",
    "\n",
    "elif args_model == 'ANP':\n",
    "    \n",
    "    noise = AddHomoNoise()\n",
    "    model = StandardANP(input_dim=args_x_dim,\n",
    "                        add_noise=noise,\n",
    "                        num_samples=args_np_loss_samples)\n",
    "    \n",
    "elif args_model == 'convNP':\n",
    "    \n",
    "    noise = AddHomoNoise()\n",
    "    model = StandardConvNP(input_dim=args_x_dim,\n",
    "                           add_noise=noise,\n",
    "                           num_samples=args_np_loss_samples)\n",
    "    \n",
    "else:\n",
    "    raise ValueError(f'Unknown model {args_model}.')\n",
    "\n",
    "\n",
    "print(f'{args_model} '\n",
    "      f'{args_covtype} '\n",
    "      f'{args_num_basis_dim}: '\n",
    "      f'{model.num_params}')\n",
    "\n",
    "with open(working_directory.file('num_params.txt'), 'w') as f:\n",
    "    f.write(f'{model.num_params}')\n",
    "        \n",
    "if args_num_params:\n",
    "    exit()\n",
    "    \n",
    "    \n",
    "# Load model to appropriate device\n",
    "model = model.to(device)\n",
    "\n",
    "latent_model = args_model in ['ANP', 'convNP', 'convNPHalfUNet']\n",
    "\n",
    "if 'eq' in args_data:\n",
    "    oracle_cov = EQ().stretch(1.)\n",
    "\n",
    "elif 'matern' in args_data:\n",
    "    oracle_cov = stheno.Matern52().stretch(1.)\n",
    "\n",
    "elif 'noisy-mixture' in args_data:\n",
    "    oracle_cov = stheno.EQ().stretch(1.) + \\\n",
    "                 stheno.EQ().stretch(0.25)\n",
    "\n",
    "elif 'weakly-periodic' in args_data:\n",
    "    oracle_cov = stheno.EQ().stretch(1.) * \\\n",
    "                 stheno.EQ().periodic(period=0.25)\n",
    "\n",
    "        \n",
    "# =============================================================================\n",
    "# Train or test model\n",
    "# =============================================================================\n",
    "\n",
    "# Number of epochs between validations\n",
    "train_iteration = 0\n",
    "log_every = 500\n",
    "\n",
    "# Create optimiser\n",
    "optimiser = torch.optim.Adam(model.parameters(),\n",
    "                         args_learning_rate,\n",
    "                         weight_decay=args_weight_decay)\n",
    "\n",
    "# Run the training loop, maintaining the best objective value\n",
    "best_nll = np.inf\n",
    "\n",
    "epochs = len(data_train)\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    print('\\nEpoch: {}/{}'.format(epoch + 1, epochs))\n",
    "\n",
    "    if epoch % args_validate_every == 0:\n",
    "\n",
    "        valid_epoch = data_val[epoch // args_validate_every]\n",
    "\n",
    "        # Compute validation negative log-likelihood\n",
    "        val_nll, _, val_oracle, _ = validate(valid_epoch,\n",
    "                                             oracle_cov,\n",
    "                                             model,\n",
    "                                             args_np_val_samples,\n",
    "                                             device,\n",
    "                                             writer,\n",
    "                                             latent_model)\n",
    "\n",
    "        # Log information to tensorboard\n",
    "        writer.add_scalar('Valid log-lik.',\n",
    "                          -val_nll,\n",
    "                          epoch)\n",
    "\n",
    "        writer.add_scalar('Valid oracle log-lik.',\n",
    "                          -val_oracle,\n",
    "                          epoch)\n",
    "\n",
    "        writer.add_scalar('Oracle minus valid log-lik.',\n",
    "                          -val_oracle + val_nll,\n",
    "                          epoch)\n",
    "\n",
    "        # Update the best objective value and checkpoint the model\n",
    "        is_best, best_obj = (True, val_nll) if val_nll < best_nll else \\\n",
    "                            (False, best_nll)\n",
    "\n",
    "        plot_marginals = args_covtype == 'meanfield'\n",
    "\n",
    "        if args_x_dim == 1:\n",
    "            \n",
    "            plot_samples_and_data(model=model,\n",
    "                                  valid_epoch=valid_epoch,\n",
    "                                  x_plot_min=-3.,\n",
    "                                  x_plot_max=3.,\n",
    "                                  root=working_directory.root,\n",
    "                                  epoch=epoch,\n",
    "                                  latent_model=latent_model,\n",
    "                                  plot_marginals=plot_marginals,\n",
    "                                  device=device)\n",
    "\n",
    "\n",
    "    train_epoch = data_train[epoch]\n",
    "\n",
    "    # Compute training negative log-likelihood\n",
    "    train_iteration = train(train_epoch,\n",
    "                            model,\n",
    "                            optimiser,\n",
    "                            log_every,\n",
    "                            device,\n",
    "                            writer,\n",
    "                            train_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc795295-c816-48e6-80d7-f47153069f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-kernelcnp",
   "language": "python",
   "name": "venv-kernelcnp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
