{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7894e7d-e9a6-4bbd-9eea-ce830e23c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from cnp.experiment import WorkingDirectory\n",
    "\n",
    "from cnp.cnp import GaussianNeuralProcess, StandardConvGNP\n",
    "from cnp.lnp import StandardConvNP\n",
    "from cnp.architectures import UNet\n",
    "\n",
    "from cnp.cov import (\n",
    "    MeanFieldGaussianLayer,\n",
    "    InnerprodGaussianLayer,\n",
    "    KvvGaussianLayer,\n",
    "    LogLogitCopulaLayer\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "from cnp.encoders import (\n",
    "    StandardEncoder,\n",
    "    ConvEncoder,\n",
    "    ConvPDEncoder,\n",
    ")\n",
    "\n",
    "from cnp.decoders import (\n",
    "    StandardDecoder,\n",
    "    ConvDecoder,\n",
    "    ConvPDDecoder,\n",
    ")\n",
    "\n",
    "from cnp.cov import GaussianLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17769b3d-743f-48b4-b721-59ffaa57cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Training epoch helper\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def train(data,\n",
    "          model,\n",
    "          optimiser,\n",
    "          log_every,\n",
    "          device,\n",
    "          writer,\n",
    "          iteration):\n",
    "    \n",
    "    for step, batch in enumerate(data):\n",
    "\n",
    "        nll = model.loss(batch['x_context'][:, :, None],\n",
    "                         batch['y_context'][:, 0, :, None] / 100 + 1e-2,\n",
    "                         batch['x_target'][:, :, None],\n",
    "                         batch['y_target'][:, 0, :, None] / 100 + 1e-2)\n",
    "\n",
    "        if step % log_every == 0:\n",
    "            print(f\"Training   neg. log-lik: {nll:.2f}\")\n",
    "\n",
    "        # Compute gradients and apply them\n",
    "        nll.backward()\n",
    "        optimiser.step()\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "#         # Write to tensorboard\n",
    "#         writer.add_scalar('Train log-lik.', - nll, iteration)\n",
    "        \n",
    "        iteration = iteration + 1\n",
    "        \n",
    "    return iteration\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Validation helper\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def validate(data,\n",
    "             model,\n",
    "             device,\n",
    "             writer,\n",
    "             latent_model):\n",
    "    \n",
    "    # Lists for logging model's training NLL and oracle NLL\n",
    "    nll_list = []\n",
    "    oracle_nll_list = []\n",
    "    \n",
    "    # If training a latent model, set the number of latent samples accordingly\n",
    "    loss_kwargs = {'num_samples' : args_np_val_samples} \\\n",
    "                  if latent_model else {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(data):\n",
    "            \n",
    "            print(batch['x_context'].shape,\n",
    "                  batch['y_context'].shape,\n",
    "                  batch['x_target'].shape,\n",
    "                  batch['y_target'].shape)\n",
    "            \n",
    "            nll = model.loss(batch['x_context'][:, :, None],\n",
    "                             batch['y_context'][:, 0, :, None] / 100 + 1e-2,\n",
    "                             batch['x_target'][:, :, None],\n",
    "                             batch['y_target'][:, 0, :, None] / 100 + 1e-2,\n",
    "                             **loss_kwargs)\n",
    "            \n",
    "            # Scale by the average number of target points\n",
    "            nll_list.append(nll.item())\n",
    "\n",
    "    mean_nll = np.mean(nll_list)\n",
    "    std_nll = np.var(nll_list)**0.5\n",
    "\n",
    "    # Print validation loss and oracle loss\n",
    "    print(f\"Validation neg. log-lik: \"\n",
    "          f\"{mean_nll:.2f}\")\n",
    "\n",
    "    return mean_nll, std_nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69f13591-2b6b-4ac4-9bdd-8aa486da07ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_data = 'sim-pred-prey-4-50-100-100-0'\n",
    "args_cov_type = 'kvv'\n",
    "args_noise_type = 'hetero'\n",
    "args_marginal_type = 'identity'\n",
    "args_model = 'convGNP'\n",
    "args_num_basis_dim = 256\n",
    "\n",
    "args_seed = 0\n",
    "args_learning_rate = 5e-4\n",
    "args_weight_decay = 0.\n",
    "args_validate_every = 1\n",
    "args_jitter = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab4e857f-99a9-481e-803a-7b4d9b2d209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardConvGNP(GaussianNeuralProcess):\n",
    "    \n",
    "    def __init__(self, input_dim, output_layer):\n",
    "        \n",
    "        # Standard input/output dimensions and discretisation density\n",
    "        output_dim = 1\n",
    "        points_per_unit = 16\n",
    "\n",
    "        conv_channels = 8\n",
    "        conv_in_channels = conv_channels\n",
    "        conv_out_channels = 8\n",
    "        \n",
    "        # Standard convolutional architecture\n",
    "        conv_architecture = UNet(input_dim=input_dim,\n",
    "                                 in_channels=conv_in_channels,\n",
    "                                 out_channels=conv_out_channels)\n",
    "\n",
    "        # Construct the convolutional encoder\n",
    "        grid_multiplyer =  2 ** conv_architecture.num_halving_layers\n",
    "        init_length_scale = 1.0 / points_per_unit\n",
    "        grid_margin = 0.2\n",
    "        \n",
    "        encoder = ConvEncoder(input_dim=input_dim,\n",
    "                              out_channels=conv_channels,\n",
    "                              init_length_scale=init_length_scale,\n",
    "                              points_per_unit=points_per_unit,\n",
    "                              grid_multiplier=grid_multiplyer,\n",
    "                              grid_margin=grid_margin)\n",
    "        \n",
    "        # Construct the convolutional decoder\n",
    "        decoder_out_channels = output_layer.num_features\n",
    "        \n",
    "        decoder = ConvDecoder(input_dim=input_dim,\n",
    "                              conv_architecture=conv_architecture,\n",
    "                              conv_out_channels=conv_architecture.out_channels,\n",
    "                              out_channels=decoder_out_channels,\n",
    "                              init_length_scale=init_length_scale,\n",
    "                              points_per_unit=points_per_unit,\n",
    "                              grid_multiplier=grid_multiplyer,\n",
    "                              grid_margin=grid_margin)\n",
    "\n",
    "\n",
    "        super().__init__(encoder=encoder,\n",
    "                         decoder=decoder,\n",
    "                         output_layer=output_layer)\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.conv_architecture = conv_architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "097e070a-e18d-4e05-a016-4546bf82d741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim-pred-prey-4-50-100-100-0 convGNP kvv hetero identity 256: 53013\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Create model\n",
    "# =============================================================================\n",
    "\n",
    "cov_types = {\n",
    "    'meanfield' : MeanFieldGaussianLayer,\n",
    "    'innerprod' : InnerprodGaussianLayer,\n",
    "    'kvv'       : KvvGaussianLayer\n",
    "}\n",
    "\n",
    "if args_cov_type == 'meanfield':\n",
    "    output_layer = MeanFieldGaussianLayer(jitter=args_jitter)\n",
    "    \n",
    "else:\n",
    "    output_layer = cov_types[args_cov_type](num_embedding=args_num_basis_dim,\n",
    "                                            noise_type=args_noise_type,\n",
    "                                            jitter=args_jitter)\n",
    "\n",
    "if args_marginal_type == 'loglogit':\n",
    "    output_layer = LogLogitCopulaLayer(gaussian_layer=output_layer)\n",
    "    \n",
    "# Create model architecture\n",
    "if args_model == 'convGNP':\n",
    "    model = StandardConvGNP(input_dim=1, output_layer=output_layer)\n",
    "    \n",
    "elif args_model == 'convNP':\n",
    "    model = StandardConvNP(input_dim=1,\n",
    "                           num_samples=args_np_loss_samples)\n",
    "    \n",
    "else:\n",
    "    raise ValueError(f'Unknown model {args_model}.')\n",
    "\n",
    "latent_model = args_model == 'convNP'\n",
    "\n",
    "print(f'{args_data} '\n",
    "      f'{args_model} '\n",
    "      f'{args_cov_type} '\n",
    "      f'{args_noise_type} '\n",
    "      f'{args_marginal_type} '\n",
    "      f'{args_num_basis_dim}: '\n",
    "      f'{model.num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71631c8a-15c7-4e63-bfcd-ebfc710b434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root: /Users/stratis/repos/kernelcnp/kernelcnp/experiments/predator-prey/results/sim-pred-prey-4-50-100-100-0/models/convGNP/kvv/hetero/identity/seed-0\n",
      "Root: /Users/stratis/repos/kernelcnp/kernelcnp/experiments/predator-prey/simulated-data/sim-pred-prey-4-50-100-100-0\n"
     ]
    }
   ],
   "source": [
    "# Set seed\n",
    "np.random.seed(args_seed)\n",
    "torch.manual_seed(args_seed)\n",
    "\n",
    "# Set device\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(args_gpu)\n",
    "    \n",
    "use_cpu = False\n",
    "device = torch.device('cpu') if use_cpu else torch.device('cuda')\n",
    "\n",
    "root = '/Users/stratis/repos/kernelcnp/kernelcnp/experiments/predator-prey'\n",
    "\n",
    "# Working directory for saving results\n",
    "experiment_name = os.path.join(f'{root}',\n",
    "                               f'results',\n",
    "                               f'{args_data}',\n",
    "                               f'models',\n",
    "                               f'{args_model}',\n",
    "                               f'{args_cov_type}',\n",
    "                               f'{args_noise_type}',\n",
    "                               f'{args_marginal_type}',\n",
    "                               f'seed-{args_seed}')\n",
    "working_directory = WorkingDirectory(root=experiment_name)\n",
    "\n",
    "# Data directory for loading data\n",
    "data_root = os.path.join(f'{root}',\n",
    "                         f'simulated-data',\n",
    "                         f'{args_data}')\n",
    "data_directory = WorkingDirectory(root=data_root)\n",
    "    \n",
    "file = open(working_directory.file('data_location.txt'), 'w')\n",
    "file.write(data_directory.root)\n",
    "file.close()\n",
    "\n",
    "# =============================================================================\n",
    "# Load data and validation oracle generator\n",
    "# =============================================================================\n",
    "    \n",
    "file = open(data_directory.file('train-data.pkl'), 'rb')\n",
    "data_train = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open(data_directory.file('valid-data.pkl'), 'rb')\n",
    "data_val = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32208b30-5987-41dc-9d66-f6baf7859968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1/11\n",
      "Training   neg. log-lik: 287.96\n",
      "Training   neg. log-lik: 87.61\n",
      "Training   neg. log-lik: 16.92\n",
      "Training   neg. log-lik: -19.92\n",
      "Training   neg. log-lik: -23.09\n",
      "Training   neg. log-lik: -34.52\n",
      "\n",
      "Epoch: 2/11\n",
      "Training   neg. log-lik: -38.32\n",
      "Training   neg. log-lik: -58.30\n",
      "Training   neg. log-lik: -1.92\n",
      "Training   neg. log-lik: -32.60\n",
      "Training   neg. log-lik: -70.63\n",
      "Training   neg. log-lik: -59.06\n",
      "\n",
      "Epoch: 3/11\n",
      "Training   neg. log-lik: -88.33\n",
      "Training   neg. log-lik: -36.45\n",
      "Training   neg. log-lik: -73.35\n",
      "Training   neg. log-lik: -48.26\n",
      "Training   neg. log-lik: -75.39\n",
      "Training   neg. log-lik: -23.93\n",
      "\n",
      "Epoch: 4/11\n",
      "Training   neg. log-lik: -94.77\n",
      "Training   neg. log-lik: -56.73\n",
      "Training   neg. log-lik: -12.13\n",
      "Training   neg. log-lik: 18.89\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Train or test model\n",
    "# =============================================================================\n",
    "\n",
    "# Number of epochs between validations\n",
    "train_iteration = 0\n",
    "log_every = 100\n",
    "\n",
    "# Create optimiser\n",
    "optimiser = torch.optim.Adam(model.parameters(),\n",
    "                         args_learning_rate,\n",
    "                         weight_decay=args_weight_decay)\n",
    "\n",
    "# Run the training loop, maintaining the best objective value\n",
    "best_nll = np.inf\n",
    "\n",
    "epochs = len(data_train)\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    print('\\nEpoch: {}/{}'.format(epoch + 1, epochs))\n",
    "\n",
    "    if False: # epoch % args_validate_every == 0:\n",
    "\n",
    "        valid_epoch = data_val[epoch // args_validate_every]\n",
    "        \n",
    "        # Compute negative log-likelihood on validation data\n",
    "        val_nll, _,  = validate(valid_epoch,\n",
    "                                model,\n",
    "                                device,\n",
    "                                None,\n",
    "                                latent_model)\n",
    "\n",
    "#         # Log information to tensorboard\n",
    "#         writer.add_scalar('True data log-lik.',\n",
    "#                           -true_nll,\n",
    "#                           epoch)\n",
    "\n",
    "#         # Log information to tensorboard\n",
    "#         writer.add_scalar('Validation log-lik.',\n",
    "#                           -val_nll,\n",
    "#                           epoch)\n",
    "\n",
    "        # Update the best objective value and checkpoint the model\n",
    "        is_best, best_obj = (True, val_nll) if val_nll < best_nll else \\\n",
    "                            (False, best_nll)\n",
    "\n",
    "\n",
    "    train_epoch = data_train[epoch]\n",
    "\n",
    "    # Compute training negative log-likelihood\n",
    "    train_iteration = train(train_epoch,\n",
    "                            model,\n",
    "                            optimiser,\n",
    "                            log_every,\n",
    "                            device,\n",
    "                            None,\n",
    "                            train_iteration)\n",
    "\n",
    "#     save_checkpoint(working_directory,\n",
    "#                     {'epoch'         : epoch + 1,\n",
    "#                      'state_dict'    : model.state_dict(),\n",
    "#                      'best_acc_top1' : best_obj,\n",
    "#                      'optimizer'     : optimiser.state_dict()},\n",
    "#                     is_best=is_best,\n",
    "#                     epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74dc2b5-2c4b-46ae-8ea4-983c6c21adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_idx = 1\n",
    "i_idx = 2\n",
    "b_idx = 0\n",
    "\n",
    "train_epoch = data_train[e_idx]\n",
    "\n",
    "x_max = torch.max(train_epoch[i_idx]['x_target'][b_idx, :])\n",
    "x_plot = torch.linspace(-5., x_max+5., 200)[None, :, None]\n",
    "x_plot = x_plot.repeat(train_epoch[i_idx]['x_context'].shape[0], 1, 1)\n",
    "\n",
    "samples = model.sample(train_epoch[i_idx]['x_context'][:, :, None],\n",
    "                       train_epoch[i_idx]['y_context'][:, 0, :, None] / 100 + 1e-2,\n",
    "                       x_plot,\n",
    "                       num_samples=100,\n",
    "                       noiseless=True)\n",
    "\n",
    "plt.plot(x_plot[0, :, 0].detach().numpy(),\n",
    "         samples[:, b_idx, :].detach().numpy().T,\n",
    "         color='green',\n",
    "         alpha=0.2,\n",
    "         zorder=1)\n",
    "\n",
    "plt.scatter(train_epoch[i_idx]['x_context'][b_idx, :].detach().numpy(),\n",
    "            train_epoch[i_idx]['y_context'][b_idx, 0, :].detach().numpy() / 100,\n",
    "            color='black',\n",
    "            zorder=2)\n",
    "\n",
    "plt.scatter(train_epoch[i_idx]['x_target'][b_idx, :].detach().numpy(),\n",
    "            train_epoch[i_idx]['y_target'][b_idx, 0, :].detach().numpy() / 100,\n",
    "            color='red',\n",
    "            zorder=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939c0cbc-02b3-41e1-b727-3bf8037d898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Softplus()(model.output_layer.noise_unconstrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9dfea1-ded6-42ee-bafb-1edf956807e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-gnp",
   "language": "python",
   "name": "venv-gnp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
