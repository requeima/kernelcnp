{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65884260-b92a-429c-98c3-b1ac86f8812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "from cnp.cnp import GaussianNeuralProcess\n",
    "from cnp.data import LambdaIterator\n",
    "from cnp.cov import MeanFieldCov, InnerProdCov, KvvCov, AddNoNoise, AddHomoNoise\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcab4651-2963-4156-b0c7-4de2258f8b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/scratches/cblgpu07/em626/kernelcnp/kernelcnp/experiments/environmental/data'\n",
    "\n",
    "np_lonlat_fine = np.load(f'{data_root}/x_context_fine.npy')\n",
    "np_lonlat_coarse = np.load(f'{data_root}/x_context_coarse.npy')\n",
    "np_elevation_fine = np.load(f'{data_root}/y_context_fine.npy')\n",
    "\n",
    "np_train_reanalysis_coarse = np.load(f'{data_root}/y_context_coarse_train.npy')\n",
    "np_train_lonlat_station = np.load(f'{data_root}/x_target_train.npy')\n",
    "np_train_temperature_station = np.load(f'{data_root}/y_target_train.npy')\n",
    "\n",
    "np_test_reanalysis_coarse = np.load(f'{data_root}/y_context_coarse_val.npy')\n",
    "np_test_lonlat_station = np.load(f'{data_root}/x_target_val.npy')\n",
    "np_test_temperature_station = np.load(f'{data_root}/y_target_val.npy')\n",
    "\n",
    "lonlat_fine = torch.tensor(np_lonlat_fine).float()\n",
    "lonlat_coarse = torch.tensor(np_lonlat_coarse).float()\n",
    "np_elevation_fine = (np_elevation_fine - np.mean(np_elevation_fine)) / np.std(np_elevation_fine)**0.5\n",
    "elevation_fine = torch.tensor(np_elevation_fine).float()\n",
    "\n",
    "idx = torch.randperm(np_train_lonlat_station.shape[0])\n",
    "train_lonlat_station = torch.tensor(np_train_lonlat_station).float()[idx, :][:-100]\n",
    "train_temperature_station = torch.tensor(np_train_temperature_station).float()[:, idx][:, :-100]\n",
    "train_reanalysis_coarse = torch.tensor(np_train_reanalysis_coarse).float()\n",
    "\n",
    "# Compute mean and standard deviation of inputs for normalising\n",
    "train_reanalysis_mean = torch.mean(train_reanalysis_coarse, dim=[0, 2, 3])[None, :, None, None]\n",
    "train_reanalysis_stds = torch.var(train_reanalysis_coarse, dim=[0, 2, 3])[None, :, None, None]**0.5\n",
    "\n",
    "train_reanalysis_coarse = (train_reanalysis_coarse - train_reanalysis_mean) / train_reanalysis_stds\n",
    "\n",
    "# Compute mean and standard deviation of outputs for normalising\n",
    "flat = torch.flatten(train_temperature_station)\n",
    "train_temperature_station_mean = torch.mean(flat[~torch.isnan(flat)])\n",
    "train_temperature_station_std = torch.var(flat[~torch.isnan(flat)])**0.5\n",
    "\n",
    "train_temperature_station = (train_temperature_station - train_temperature_station_mean) / \\\n",
    "                            train_temperature_station_std\n",
    "\n",
    "valid_lonlat_station = torch.tensor(np_train_lonlat_station).float()[idx, :][-100:]\n",
    "valid_temperature_station = torch.tensor(np_train_temperature_station).float()[:, idx][:, -100:]\n",
    "valid_reanalysis_coarse = torch.tensor(np_train_reanalysis_coarse).float()\n",
    "valid_reanalysis_coarse = (valid_reanalysis_coarse - train_reanalysis_mean) / train_reanalysis_stds\n",
    "\n",
    "valid_temperature_station = (valid_temperature_station - train_temperature_station_mean) / \\\n",
    "                            train_temperature_station_std\n",
    "\n",
    "test_lonlat_station = torch.tensor(np_test_lonlat_station).float()\n",
    "test_temperature_station = torch.tensor(np_test_temperature_station).float()\n",
    "test_reanalysis_coarse = torch.tensor(np_test_reanalysis_coarse).float()\n",
    "test_reanalysis_coarse = (test_reanalysis_coarse - train_reanalysis_mean) / train_reanalysis_stds\n",
    "\n",
    "test_temperature_station = (test_temperature_station - train_temperature_station_mean) / \\\n",
    "                            train_temperature_station_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c675859b-e837-42a2-bba9-06b4bf3d5f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lonlat_fine                    torch.Size([1200, 1200, 2])\n",
      "lonlat_coarse                  torch.Size([6, 6, 2])\n",
      "elevation_fine                 torch.Size([1200, 1200]) \n",
      "\n",
      "train_reanalysis_coarse        torch.Size([8766, 25, 6, 6])\n",
      "train_lonlat_station           torch.Size([862, 2])\n",
      "train_temperature_station      torch.Size([8766, 862]) \n",
      "\n",
      "valid_reanalysis_coarse        torch.Size([8766, 25, 6, 6])\n",
      "valid_lonlat_station           torch.Size([100, 2])\n",
      "valid_temperature_station      torch.Size([8766, 100]) \n",
      "\n",
      "test_reanalysis_coarse         torch.Size([2192, 25, 6, 6])\n",
      "test_lonlat_station            torch.Size([24, 2])\n",
      "test_temperature_station       torch.Size([11688, 24])\n"
     ]
    }
   ],
   "source": [
    "print('lonlat_fine'.ljust(30), lonlat_fine.shape)\n",
    "print('lonlat_coarse'.ljust(30), lonlat_coarse.shape)\n",
    "print('elevation_fine'.ljust(30), elevation_fine.shape, '\\n')\n",
    "\n",
    "print('train_reanalysis_coarse'.ljust(30), train_reanalysis_coarse.shape)\n",
    "print('train_lonlat_station'.ljust(30), train_lonlat_station.shape)\n",
    "print('train_temperature_station'.ljust(30), train_temperature_station.shape, '\\n')\n",
    "\n",
    "print('valid_reanalysis_coarse'.ljust(30), valid_reanalysis_coarse.shape)\n",
    "print('valid_lonlat_station'.ljust(30), valid_lonlat_station.shape)\n",
    "print('valid_temperature_station'.ljust(30), valid_temperature_station.shape, '\\n')\n",
    "\n",
    "print('test_reanalysis_coarse'.ljust(30), test_reanalysis_coarse.shape)\n",
    "print('test_lonlat_station'.ljust(30), test_lonlat_station.shape)\n",
    "print('test_temperature_station'.ljust(30), test_temperature_station.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f41b299-07f8-4800-bf43-5a5f275d6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reanalysis_means = torch.mean(train_reanalysis_coarse, axis=[0, 2, 3])[None, :, None, None]\n",
    "# reanalysis_stds = torch.var(train_reanalysis_coarse, axis=[0, 2, 3])[None, :, None, None] ** 0.5\n",
    "\n",
    "# temperature_means = torch.mean(train_temperature_station, axis=[0, 1])[None, None]\n",
    "# temperature_stds = torch.var(train_temperature_station, axis=[0, 1])[None, None] ** 0.5\n",
    "\n",
    "# train_reanalysis_coarse = (train_reanalysis_coarse - reanalysis_means) / reanalysis_stds\n",
    "# train_temperature_station = (train_temperature_station - temperature_means) / temperature_stds\n",
    "\n",
    "# valid_reanalysis_coarse = (valid_reanalysis_coarse - reanalysis_means) / reanalysis_stds\n",
    "# valid_temperature_station = (valid_temperature_station - temperature_means) / temperature_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bab440a-43a3-414c-a3a5-a5fc5ee0f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 lonlat_fine,\n",
    "                 lonlat_coarse,\n",
    "                 elevation_fine,\n",
    "                 reanalysis_coarse,\n",
    "                 lonlat_station,\n",
    "                 temperature_station,\n",
    "                 iterations_per_epoch,\n",
    "                 max_num_target,\n",
    "                 batch_size,\n",
    "                 device):\n",
    "        \n",
    "        # Set data tensors\n",
    "        self.lonlat_fine = lonlat_fine\n",
    "        self.lonlat_coarse = lonlat_coarse\n",
    "        self.elevation_fine = elevation_fine\n",
    "        self.reanalysis_coarse = reanalysis_coarse\n",
    "        self.lonlat_station = lonlat_station\n",
    "        self.temperature_station = temperature_station\n",
    "        \n",
    "        # Set dataloader parameters\n",
    "        self.iterations_per_epoch = iterations_per_epoch\n",
    "        self.max_num_target = max_num_target\n",
    "        self.num_datasets = self.reanalysis_coarse.shape[0]\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        \n",
    "        \n",
    "    def generate_batch(self):\n",
    "        \n",
    "        # Draw batch indices at random - these are time indices\n",
    "        idx1 = torch.randperm(self.num_datasets)[:batch_size]\n",
    "        \n",
    "        batch_reanalysis_coarse = self.reanalysis_coarse[idx1]\n",
    "        batch_temperature_station = self.temperature_station[idx1]\n",
    "        \n",
    "        # Keep stations which have no nan values\n",
    "        nan_mask = torch.isnan(torch.sum(batch_temperature_station, dim=0))\n",
    "        \n",
    "        batch_lonlat_station = self.lonlat_station[~nan_mask, :]\n",
    "        batch_temperature_station = batch_temperature_station[:, ~nan_mask]\n",
    "        \n",
    "        # From the non-nan stations, pick **num_target** at random\n",
    "        num_target = min(max_num_target, nan_mask.shape[0])\n",
    "        idx2 = torch.randperm(batch_lonlat_station.shape[0])[:num_target]\n",
    "        \n",
    "        batch_lonlat_station = batch_lonlat_station[idx2, :]\n",
    "        batch_temperature_station = batch_temperature_station[:, idx2]\n",
    "        \n",
    "        a = torch.cuda.memory_allocated('cuda:1')\n",
    "        if False: print(f'Memory usage (before loading):'.ljust(50) + f'{a}')\n",
    "        \n",
    "        batch = {'lonlat_fine'         : self.lonlat_fine.to(self.device),\n",
    "                 'lonlat_coarse'       : self.lonlat_coarse.to(self.device),\n",
    "                 'elevation_fine'      : self.elevation_fine.to(self.device),\n",
    "                 'reanalysis_coarse'   : batch_reanalysis_coarse.to(self.device),\n",
    "                 'lonlat_station'      : batch_lonlat_station.to(self.device),\n",
    "                 'temperature_station' : batch_temperature_station.to(self.device)}\n",
    "        \n",
    "        \n",
    "        a = torch.cuda.memory_allocated('cuda:1')\n",
    "        if False: print(f'Memory usage (after loading):'.ljust(50) + f'{a}')\n",
    "        \n",
    "        return batch\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return LambdaIterator(lambda: self.generate_batch(), self.iterations_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe8b6faa-bf68-4246-8bae-64053e34336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardEnvUNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 latent_channels,\n",
    "                 out_channels):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.latent_channels = latent_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = 5\n",
    "        self.padding = (self.kernel_size - 1) // 2\n",
    "        \n",
    "        self.l1 = nn.Conv2d(in_channels=self.in_channels,\n",
    "                            out_channels=self.latent_channels,\n",
    "                            kernel_size=self.kernel_size,\n",
    "                            padding=self.padding,\n",
    "                            stride=2)\n",
    "        \n",
    "        self.l2 = nn.Conv2d(in_channels=self.latent_channels,\n",
    "                            out_channels=2*self.latent_channels,\n",
    "                            kernel_size=self.kernel_size,\n",
    "                            padding=self.padding,\n",
    "                            stride=2)\n",
    "        \n",
    "        self.l3 = nn.Conv2d(in_channels=2*self.latent_channels,\n",
    "                            out_channels=4*self.latent_channels,\n",
    "                            kernel_size=self.kernel_size,\n",
    "                            padding=self.padding,\n",
    "                            stride=2)\n",
    "        \n",
    "        self.l4 = nn.Conv2d(in_channels=4*self.latent_channels,\n",
    "                            out_channels=4*self.latent_channels,\n",
    "                            kernel_size=self.kernel_size,\n",
    "                            padding=self.padding,\n",
    "                            stride=2)\n",
    "        \n",
    "        self.l5 = nn.Conv2d(in_channels=4*self.latent_channels,\n",
    "                            out_channels=8*self.latent_channels,\n",
    "                            kernel_size=self.kernel_size,\n",
    "                            padding=self.padding,\n",
    "                            stride=3)\n",
    "        \n",
    "        self.l6 = nn.ConvTranspose2d(in_channels=8*self.latent_channels,\n",
    "                                     out_channels=4*self.latent_channels,\n",
    "                                     kernel_size=self.kernel_size,\n",
    "                                     stride=3,\n",
    "                                     padding=self.padding,\n",
    "                                     output_padding=2)\n",
    "        \n",
    "        self.l7 = nn.ConvTranspose2d(in_channels=8*self.latent_channels,\n",
    "                                     out_channels=4*self.latent_channels,\n",
    "                                     kernel_size=self.kernel_size,\n",
    "                                     stride=2,\n",
    "                                     padding=self.padding,\n",
    "                                     output_padding=1)\n",
    "        \n",
    "        self.l8 = nn.ConvTranspose2d(in_channels=8*self.latent_channels,\n",
    "                                     out_channels=2*self.latent_channels,\n",
    "                                     kernel_size=self.kernel_size,\n",
    "                                     stride=2,\n",
    "                                     padding=self.padding,\n",
    "                                     output_padding=1)\n",
    "        \n",
    "        self.l9 = nn.ConvTranspose2d(in_channels=4*self.latent_channels,\n",
    "                                     out_channels=2*self.latent_channels,\n",
    "                                     kernel_size=self.kernel_size,\n",
    "                                     stride=2,\n",
    "                                     padding=self.padding,\n",
    "                                     output_padding=1)\n",
    "        \n",
    "        self.l10 = nn.ConvTranspose2d(in_channels=3*self.latent_channels,\n",
    "                                      out_channels=self.latent_channels,\n",
    "                                      kernel_size=self.kernel_size,\n",
    "                                      stride=2,\n",
    "                                      padding=self.padding,\n",
    "                                      output_padding=1)\n",
    "\n",
    "        self.last_multiplier = nn.Conv2d(in_channels=self.in_channels+self.latent_channels,\n",
    "                                         out_channels=self.out_channels,\n",
    "                                         kernel_size=1,\n",
    "                                         stride=1,\n",
    "                                         padding=0)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self, tensor):\n",
    "        \n",
    "        h1 = self.activation(self.l1(tensor))\n",
    "        h2 = self.activation(self.l2(h1))\n",
    "        h3 = self.activation(self.l3(h2))\n",
    "        h4 = self.activation(self.l4(h3))\n",
    "        h5 = self.activation(self.l5(h4))\n",
    "        \n",
    "        h6 = self.activation(self.l6(h5))\n",
    "        h6 = torch.cat([h4, h6], dim=1)\n",
    "        \n",
    "        h7 = self.activation(self.l7(h6))\n",
    "        h7 = torch.cat([h3, h7], dim=1)\n",
    "        \n",
    "        h8 = self.activation(self.l8(h7))\n",
    "        h8 = torch.cat([h2, h8], dim=1)\n",
    "        \n",
    "        h9 = self.activation(self.l9(h8))\n",
    "        h9 = torch.cat([h1, h9], dim=1)\n",
    "        \n",
    "        h10 = self.activation(self.l10(h9))\n",
    "        h10 = torch.cat([tensor, h10], dim=1)\n",
    "        \n",
    "        output = self.last_multiplier(h10)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f98f2d7-fef8-4bed-86a8-66f477562dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardEnvUpscaleEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, lengthscale):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.lengthscale = nn.Parameter(torch.tensor([lengthscale, lengthscale]))\n",
    "\n",
    "        \n",
    "    def convert_to_fine(self, tensor, lonlat_coarse, lonlat_fine):\n",
    "        \"\"\"\n",
    "        Upscales **tensor** with corresponding coordinates **lonlat_coarse**\n",
    "        to a finer discretisation with coordinates **lonlat_fine**.\n",
    "        \n",
    "        Arguments:\n",
    "        \n",
    "            tensor        : torch.tensor, shape (B, C, K, L)\n",
    "            lonlat_coarse : torch.tensor, shape (K, L, 2)\n",
    "            lonlat_fine   : torch.tensor, shape (N, M, 2)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute differences between grid locations\n",
    "        diff = lonlat_coarse[:, :, None, None, :] - \\\n",
    "               lonlat_fine[None, None, :, :, :]\n",
    "        \n",
    "        # Compute weight matrix\n",
    "        quad = -0.5 * (diff / self.lengthscale[None, None, None, None, :]) ** 2\n",
    "        quad = torch.sum(quad, axis=-1)\n",
    "        exp = torch.exp(quad)\n",
    "        exp = exp / torch.sum(exp, dim=[0, 1])[None, None, :]\n",
    "        \n",
    "        # Compute refined tensor\n",
    "        tensor = torch.einsum('bckl, klnm -> bcnm', tensor, exp)\n",
    "        \n",
    "        return tensor\n",
    "    \n",
    "        \n",
    "    def forward(self,\n",
    "                lonlat_fine,\n",
    "                elevation_fine,\n",
    "                lonlat_coarse,\n",
    "                reanalysis_coarse):\n",
    "        \n",
    "        # Get number of batches\n",
    "        B = reanalysis_coarse.shape[0]\n",
    "        elevation_fine = elevation_fine[None, None, :, :].repeat(B, 1, 1, 1)\n",
    "        \n",
    "        # Upscale reanalysis data to match elevation grid\n",
    "        reanalysis_fine = self.convert_to_fine(tensor=reanalysis_coarse,\n",
    "                                               lonlat_coarse=lonlat_coarse,\n",
    "                                               lonlat_fine=lonlat_fine)\n",
    "        \n",
    "        # Concatenate reanalysis and elevation\n",
    "        tensor = torch.cat([reanalysis_fine, 0.*elevation_fine], axis=1)\n",
    "        \n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9a6a5b2-c7bf-42de-b501-108fcc574e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardEnvDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, lengthscale, out_channels):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_in_channels = 26\n",
    "        self.conv_latent_channels = 8\n",
    "        self.conv_out_channels = 8\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.lengthscale = nn.Parameter(torch.tensor([lengthscale, lengthscale]))\n",
    "        \n",
    "        self.cnn = StandardEnvUNet(in_channels=self.conv_in_channels,\n",
    "                                   latent_channels=self.conv_latent_channels,\n",
    "                                   out_channels=self.conv_out_channels)\n",
    "\n",
    "        self.l1 = nn.Linear(in_features=self.conv_out_channels+1,\n",
    "                            out_features=self.out_channels,\n",
    "                            bias=True)\n",
    "\n",
    "        self.l2 = nn.Linear(in_features=self.out_channels,\n",
    "                            out_features=self.out_channels,\n",
    "                            bias=True)\n",
    "\n",
    "        self.l3 = nn.Linear(in_features=self.out_channels,\n",
    "                            out_features=self.out_channels,\n",
    "                            bias=True)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "\n",
    "    def forward(self, tensor, elevation_fine, lonlat_fine, lonlat_target):\n",
    "        \"\"\"\n",
    "        \n",
    "        Arguments:\n",
    "        \n",
    "            tensor        : torch.tensor, shape (B, C1, K, L)\n",
    "            lonlat_fine   : torch.tensor, shape (K, L, 2)\n",
    "            lonlat_target : torch.tensor, shape (N, 2)\n",
    "            \n",
    "        Returns:\n",
    "            tensor        : torch.tensor, shape (B, C2, N)\n",
    "        \"\"\"\n",
    "        \n",
    "        B = tensor.shape[0]\n",
    "        elevation_fine = elevation_fine[None, None, :, :].repeat(B, 1, 1, 1)\n",
    "        \n",
    "        tensor = self.cnn(tensor)\n",
    "        \n",
    "        # Compute differences between grid locations\n",
    "        diff = lonlat_fine[:, :, None, :] - \\\n",
    "               lonlat_target[None, None, :, :]\n",
    "        \n",
    "        # Compute weight matrix\n",
    "        quad = -0.5 * (diff / self.lengthscale[None, None, None, :]) ** 2\n",
    "        \n",
    "        quad = torch.sum(quad, axis=-1)\n",
    "        exp = torch.exp(quad)\n",
    "        exp = exp / torch.sum(exp, dim=[0, 1])[None, None, :]\n",
    "        \n",
    "        # Compute refined tensor\n",
    "        tensor = torch.cat([tensor, elevation_fine], dim=1)\n",
    "        tensor = torch.einsum('bckl, kln -> bcn', tensor, exp)\n",
    "        \n",
    "        tensor = torch.permute(tensor, (0, 2, 1))\n",
    "        tensor = self.l1(tensor)\n",
    "        tensor = self.activation(tensor)\n",
    "        tensor = self.l2(tensor) + tensor\n",
    "        tensor = self.activation(tensor)\n",
    "        tensor = self.l3(tensor) + tensor\n",
    "        \n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdfb8744-f6de-41b9-952c-13093e27b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvUpscaleConvGNP(GaussianNeuralProcess):\n",
    "    \n",
    "    def __init__(self, covariance, add_noise):\n",
    "        \n",
    "        self.output_dim = 1\n",
    "        self.encoder_lengthscale = 1.5\n",
    "        self.decoder_lengthscale = 0.05\n",
    "        \n",
    "        # Construct the convolutional decoder\n",
    "        decoder_out_channels = self.output_dim          + \\\n",
    "                               covariance.num_basis_dim + \\\n",
    "                               covariance.extra_cov_dim + \\\n",
    "                               add_noise.extra_noise_dim\n",
    "        \n",
    "        encoder = StandardEnvUpscaleEncoder(lengthscale=self.encoder_lengthscale)\n",
    "        \n",
    "        decoder = StandardEnvDecoder(lengthscale=self.decoder_lengthscale,\n",
    "                                     out_channels=decoder_out_channels)\n",
    "\n",
    "        super().__init__(encoder=encoder,\n",
    "                         decoder=decoder,\n",
    "                         covariance=covariance,\n",
    "                         add_noise=add_noise)\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        # Pass through encoder\n",
    "        tensor = self.encoder(lonlat_fine=batch['lonlat_fine'],\n",
    "                              elevation_fine=batch['elevation_fine'],\n",
    "                              lonlat_coarse=batch['lonlat_coarse'],\n",
    "                              reanalysis_coarse=batch['reanalysis_coarse'])\n",
    "        \n",
    "        # Pass through decoder\n",
    "        tensor = self.decoder(tensor,\n",
    "                              elevation_fine=batch['elevation_fine'],\n",
    "                              lonlat_fine=batch['lonlat_fine'],\n",
    "                              lonlat_target=batch['lonlat_station'])\n",
    "        \n",
    "        # Produce mean\n",
    "        mean = tensor[..., 0:1]\n",
    "        \n",
    "        # Produce cov\n",
    "        embedding = tensor[..., 1:]\n",
    "        cov = self.covariance(embedding)\n",
    "        cov_plus_noise = self.add_noise(cov, embedding)\n",
    "        \n",
    "        return mean, cov, cov_plus_noise\n",
    "\n",
    "    \n",
    "    def loss(self, batch):\n",
    "\n",
    "        y_mean, _, y_cov = self.forward(batch)\n",
    "\n",
    "        y_mean = y_mean.double()\n",
    "        y_cov = y_cov.double()\n",
    "        y_target = batch['temperature_station'].double()\n",
    "\n",
    "        jitter = 1e-3 * torch.eye(y_cov.shape[-1], device=y_cov.device).double()\n",
    "        y_cov = y_cov + jitter[None, :, :]\n",
    "        \n",
    "        mae = torch.mean(torch.abs(y_mean[:, :, 0] - y_target))\n",
    "        \n",
    "        dist = MultivariateNormal(loc=y_mean[:, :, 0],\n",
    "                                  covariance_matrix=y_cov)\n",
    "        nll = - torch.mean(dist.log_prob(y_target.double()))\n",
    "\n",
    "        return nll.float(), mae.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a98c5cae-90ac-4b38-ac39-607577d52b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "921c468c-c665-42d3-8bba-e74b781f2c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations_per_epoch = 5000\n",
    "batch_size = 8\n",
    "max_num_target = 8\n",
    "\n",
    "test_batch_size = 4\n",
    "test_max_num_target = 24\n",
    "\n",
    "train_data = Dataloader(lonlat_fine=lonlat_fine,\n",
    "                        lonlat_coarse=lonlat_coarse,\n",
    "                        elevation_fine=elevation_fine,\n",
    "                        reanalysis_coarse=train_reanalysis_coarse,\n",
    "                        lonlat_station=train_lonlat_station,\n",
    "                        temperature_station=train_temperature_station,\n",
    "                        iterations_per_epoch=iterations_per_epoch,\n",
    "                        max_num_target=max_num_target,\n",
    "                        batch_size=batch_size,\n",
    "                        device=device)\n",
    "\n",
    "valid_data = Dataloader(lonlat_fine=lonlat_fine,\n",
    "                        lonlat_coarse=lonlat_coarse,\n",
    "                        elevation_fine=elevation_fine,\n",
    "                        reanalysis_coarse=valid_reanalysis_coarse,\n",
    "                        lonlat_station=valid_lonlat_station,\n",
    "                        temperature_station=valid_temperature_station,\n",
    "                        iterations_per_epoch=iterations_per_epoch,\n",
    "                        max_num_target=max_num_target,\n",
    "                        batch_size=batch_size,\n",
    "                        device=device)\n",
    "\n",
    "test_data = Dataloader(lonlat_fine=lonlat_fine,\n",
    "                       lonlat_coarse=lonlat_coarse,\n",
    "                       elevation_fine=elevation_fine,\n",
    "                       reanalysis_coarse=test_reanalysis_coarse,\n",
    "                       lonlat_station=test_lonlat_station,\n",
    "                       temperature_station=test_temperature_station,\n",
    "                       iterations_per_epoch=iterations_per_epoch,\n",
    "                       max_num_target=test_max_num_target,\n",
    "                       batch_size=test_batch_size,\n",
    "                       device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef86bc87-8f44-4c36-bc90-10eeb8cfe20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 16.59, 24.00, 23.01 MAE: 10.27, 18.75, 13.81 Encoder scale: 1.50, 1.50 Decoder scale: 0.05, 0.05 \n",
      "Loss: 18.44, 18.48, 20.52 MAE: 9.42, 9.01, 10.40 Encoder scale: 1.51, 1.50 Decoder scale: 0.05, 0.05 \n",
      "Loss: 14.25, 21.66, 20.15 MAE: 7.70, 12.30, 8.87 Encoder scale: 1.51, 1.49 Decoder scale: 0.05, 0.05 \n",
      "Loss: 13.43, 22.02, 11.88 MAE: 7.34, 11.66, 4.78 Encoder scale: 1.51, 1.49 Decoder scale: 0.05, 0.05 \n",
      "Loss: 14.47, 14.58, 18.79 MAE: 7.06, 8.26, 9.38 Encoder scale: 1.51, 1.49 Decoder scale: 0.05, 0.05 \n",
      "Loss: 14.60, 13.29, 11.75 MAE: 7.14, 6.98, 6.02 Encoder scale: 1.51, 1.49 Decoder scale: 0.05, 0.05 \n",
      "Loss: 12.08, 10.70, 23.87 MAE: 5.17, 4.38, 12.05 Encoder scale: 1.51, 1.49 Decoder scale: 0.05, 0.05 \n",
      "Loss: 16.50, 13.46, 17.47 MAE: 9.57, 5.99, 8.84 Encoder scale: 1.51, 1.49 Decoder scale: 0.05, 0.05 \n",
      "Loss: 12.34, 12.76, 15.39 MAE: 6.11, 6.04, 7.82 Encoder scale: 1.51, 1.49 Decoder scale: 0.05, 0.05 \n",
      "Loss: 19.21, 14.30, 14.12 MAE: 11.68, 6.71, 7.33 Encoder scale: 1.51, 1.49 Decoder scale: 0.05, 0.05 \n",
      "Loss: 21.20, 17.68, 18.68 MAE: 12.52, 8.36, 10.34 Encoder scale: 1.51, 1.49 Decoder scale: 0.05, 0.05 \n",
      "Loss: 10.60, 12.43, 14.92 MAE: 4.02, 5.81, 7.54 Encoder scale: 1.51, 1.49 Decoder scale: 0.05, 0.05 \n",
      "Loss: 13.25, 27.14, 16.48 MAE: 7.13, 13.64, 8.15 Encoder scale: 1.51, 1.49 Decoder scale: 0.05, 0.05 \n",
      "Loss: 19.51, 13.12, 14.08 MAE: 9.98, 6.93, 7.30 Encoder scale: 1.51, 1.49 Decoder scale: 0.05, 0.05 \n",
      "Loss: 10.77, 13.63, 17.53 MAE: 4.50, 6.21, 8.91 Encoder scale: 1.51, 1.49 Decoder scale: 0.05, 0.05 \n",
      "Loss: 14.46, 21.30, 19.84 MAE: 7.05, 11.35, 10.42 Encoder scale: 1.51, 1.49 Decoder scale: 0.05, 0.05 \n",
      "Loss: 17.69, 12.11, 20.73 MAE: 9.50, 5.47, 11.83 Encoder scale: 1.51, 1.49 Decoder scale: 0.05, 0.05 \n",
      "Loss: 15.04, 16.37, 15.91 MAE: 8.37, 9.84, 8.56 Encoder scale: 1.51, 1.49 Decoder scale: 0.05, 0.05 \n",
      "Loss: 15.26, 14.27, 16.78 MAE: 9.21, 6.39, 8.93 Encoder scale: 1.51, 1.49 Decoder scale: 0.05, 0.05 \n",
      "Loss: 15.64, 11.43, 19.53 MAE: 8.83, 5.12, 9.56 Encoder scale: 1.51, 1.49 Decoder scale: 0.05, 0.05 \n"
     ]
    }
   ],
   "source": [
    "num_basis_dim = 128\n",
    "\n",
    "# covariance = KvvCov(num_basis_dim)\n",
    "# add_noise = AddHomoNoise()\n",
    "\n",
    "covariance = MeanFieldCov(num_basis_dim=1)\n",
    "add_noise = AddNoNoise()\n",
    "\n",
    "model = EnvUpscaleConvGNP(covariance=covariance,\n",
    "                          add_noise=add_noise)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(lr=5e-4, params=model.parameters()) #, weight_decay=1e-4)\n",
    "\n",
    "mae_scale = train_temperature_station_std\n",
    "\n",
    "for i, (train_batch, valid_batch, test_batch) in enumerate(zip(train_data, valid_data, test_data)):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss, mae = model.loss(train_batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            valid_loss, valid_mae = model.loss(valid_batch)\n",
    "            test_loss, test_mae = model.loss(test_batch)\n",
    "            \n",
    "        encoder_scale = model.encoder.lengthscale.detach().cpu().numpy()\n",
    "        decoder_scale = model.decoder.lengthscale.detach().cpu().numpy()\n",
    "            \n",
    "        print(f'Loss: {loss:4.2f}, {valid_loss:4.2f}, {test_loss:4.2f} '\n",
    "              f'MAE: {mae*mae_scale:4.2f}, {valid_mae*mae_scale:4.2f}, {test_mae*mae_scale:4.2f} '\n",
    "              f'Encoder scale: {encoder_scale[0]:.2f}, {encoder_scale[1]:.2f} '\n",
    "              f'Decoder scale: {decoder_scale[0]:.2f}, {decoder_scale[1]:.2f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29583a5-a9f8-4963-80c6-ee1f525c59f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16, 20))\n",
    "# for i in range(80):\n",
    "    \n",
    "#     plt.subplot(10, 8, i+1)\n",
    "#     temp = train_temperature_station[:, i].numpy()\n",
    "#     temp = temp[~np.isnan(temp)]\n",
    "    \n",
    "#     plt.hist(temp)\n",
    "    \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bdca52-d4da-480d-a032-70cbc62fc5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_lonlat_station[:, 0],\n",
    "            train_lonlat_station[:, 1],\n",
    "            zorder=2)\n",
    "\n",
    "plt.scatter(train_lonlat_station[:, 0],\n",
    "            train_lonlat_station[:, 1],\n",
    "            zorder=2)\n",
    "\n",
    "plt.scatter(valid_lonlat_station[:, 0],\n",
    "            valid_lonlat_station[:, 1],\n",
    "            zorder=3)\n",
    "\n",
    "plt.contourf(lonlat_fine[:, :, 0],\n",
    "             lonlat_fine[:, :, 1],\n",
    "             elevation_fine, origin='lower',\n",
    "             alpha=0.5,\n",
    "             cmap='coolwarm',\n",
    "             zorder=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e845c95-6d7e-47e3-8708-24378a6e082c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-kernelcnp",
   "language": "python",
   "name": "venv-kernelcnp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
