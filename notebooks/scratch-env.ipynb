{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65884260-b92a-429c-98c3-b1ac86f8812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from cnp.data import LambdaIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcab4651-2963-4156-b0c7-4de2258f8b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/scratches/cblgpu07/em626/kernelcnp/kernelcnp/experiments/environmental/data'\n",
    "\n",
    "lonlat_fine = np.load(f'{data_root}/x_context_fine.npy')\n",
    "lonlat_coarse = np.load(f'{data_root}/x_context_coarse.npy')\n",
    "elevation_fine = np.load(f'{data_root}/y_context_fine.npy')\n",
    "\n",
    "train_reanalysis_coarse = np.load(f'{data_root}/y_context_coarse_train.npy')\n",
    "train_lonlat_station = np.load(f'{data_root}/x_target_train.npy')\n",
    "train_temperature_station = np.load(f'{data_root}/y_target_train.npy')\n",
    "\n",
    "valid_reanalysis_coarse = np.load(f'{data_root}/y_context_coarse_val.npy')\n",
    "valid_lonlat_station = np.load(f'{data_root}/x_target_val.npy')\n",
    "valid_temperature_station = np.load(f'{data_root}/y_target_val.npy')\n",
    "\n",
    "lonlat_fine = torch.tensor(lonlat_fine).float()\n",
    "lonlat_coarse = torch.tensor(lonlat_coarse).float()\n",
    "elevation_fine = torch.tensor(elevation_fine).float()\n",
    "\n",
    "train_reanalysis_coarse = torch.tensor(train_reanalysis_coarse).float()\n",
    "train_lonlat_station = torch.tensor(train_lonlat_station).float()\n",
    "train_temperature_station = torch.tensor(train_temperature_station).float()\n",
    "\n",
    "valid_reanalysis_coarse = torch.tensor(valid_reanalysis_coarse).float()\n",
    "valid_lonlat_station = torch.tensor(valid_lonlat_station).float()\n",
    "valid_temperature_station = torch.tensor(valid_temperature_station).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c675859b-e837-42a2-bba9-06b4bf3d5f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('lonlat_fine'.ljust(30), lonlat_fine.shape)\n",
    "print('lonlat_coarse'.ljust(30), lonlat_coarse.shape)\n",
    "print('elevation_fine'.ljust(30), elevation_fine.shape, '\\n')\n",
    "\n",
    "print('train_reanalysis_coarse'.ljust(30), train_reanalysis_coarse.shape)\n",
    "print('train_lonlat_station'.ljust(30), train_lonlat_station.shape)\n",
    "print('train_temperature_station'.ljust(30), train_temperature_station.shape, '\\n')\n",
    "\n",
    "print('valid_reanalysis_coarse'.ljust(30), valid_reanalysis_coarse.shape)\n",
    "print('valid_lonlat_station'.ljust(30), valid_lonlat_station.shape)\n",
    "print('valid_temperature_station'.ljust(30), valid_temperature_station.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bab440a-43a3-414c-a3a5-a5fc5ee0f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 lonlat_fine,\n",
    "                 lonlat_coarse,\n",
    "                 elevation_fine,\n",
    "                 reanalysis_coarse,\n",
    "                 lonlat_station,\n",
    "                 temperature_station,\n",
    "                 iterations_per_epoch,\n",
    "                 batch_size):\n",
    "        \n",
    "        # Set data tensors\n",
    "        self.lonlat_fine = lonlat_fine\n",
    "        self.lonlat_coarse = lonlat_coarse\n",
    "        self.elevation_fine = elevation_fine\n",
    "        self.reanalysis_coarse = reanalysis_coarse\n",
    "        self.lonlat_station = lonlat_station\n",
    "        self.temperature_station = temperature_station\n",
    "        \n",
    "        # Set dataloader parameters\n",
    "        self.iterations_per_epoch = iterations_per_epoch\n",
    "        self.num_datasets = self.reanalysis_coarse.shape[0]\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        \n",
    "    def generate_batch(self):\n",
    "        \n",
    "        # Draw batch indices at random\n",
    "        idx = torch.randperm(self.num_datasets)[:batch_size]\n",
    "        \n",
    "        # Select batch indices\n",
    "        batch_reanalysis_coarse = self.reanalysis_coarse[idx]\n",
    "        batch_temperature_station = self.temperature_station[idx]\n",
    "        \n",
    "        # Keep non-nan stations\n",
    "        nan_mask = torch.isnan(torch.sum(batch_temperature_station, dim=0))\n",
    "        \n",
    "        batch_lonlat_station = self.lonlat_station[~nan_mask, :]\n",
    "        batch_temperature_station = batch_temperature_station[:, ~nan_mask]\n",
    "        \n",
    "        batch = {'lonlat_fine'         : self.lonlat_fine,\n",
    "                 'lonlat_coarse'       : self.lonlat_coarse,\n",
    "                 'elevation_fine'      : self.elevation_fine,\n",
    "                 'reanalysis_coarse'   : batch_reanalysis_coarse,\n",
    "                 'lonlat_station'      : batch_lonlat_station,\n",
    "                 'temperature_station' : batch_temperature_station}\n",
    "        \n",
    "        return batch\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return LambdaIterator(lambda: self.generate_batch(), self.iterations_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b6faa-bf68-4246-8bae-64053e34336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardEnvUNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 latent_channels,\n",
    "                 out_channels):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.latent_channels = latent_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = 5\n",
    "        self.padding = 2\n",
    "        \n",
    "        self.l1 = nn.Conv2d(in_channels=self.in_channels,\n",
    "                            out_channels=self.latent_channels,\n",
    "                            kernel_size=self.kernel_size,\n",
    "                            padding=self.padding,\n",
    "                            stride=2)\n",
    "        \n",
    "        self.l2 = nn.Conv2d(in_channels=self.latent_channels,\n",
    "                            out_channels=2*self.latent_channels,\n",
    "                            kernel_size=self.kernel_size,\n",
    "                            padding=self.padding,\n",
    "                            stride=2)\n",
    "        \n",
    "        self.l3 = nn.Conv2d(in_channels=2*self.latent_channels,\n",
    "                            out_channels=4*self.latent_channels,\n",
    "                            kernel_size=self.kernel_size,\n",
    "                            padding=self.padding,\n",
    "                            stride=2)\n",
    "        \n",
    "        self.l4 = nn.Conv2d(in_channels=4*self.latent_channels,\n",
    "                            out_channels=8*self.latent_channels,\n",
    "                            kernel_size=self.kernel_size,\n",
    "                            padding=self.padding,\n",
    "                            stride=2)\n",
    "        \n",
    "        self.l5 = nn.ConvTranspose2d(in_channels=8*self.latent_channels,\n",
    "                                     out_channels=4*self.latent_channels,\n",
    "                                     kernel_size=self.kernel_size,\n",
    "                                     stride=2,\n",
    "                                     padding=2,\n",
    "                                     output_padding=1)\n",
    "        \n",
    "        self.l6 = nn.ConvTranspose2d(in_channels=8*self.latent_channels,\n",
    "                                     out_channels=2*self.latent_channels,\n",
    "                                     kernel_size=self.kernel_size,\n",
    "                                     stride=2,\n",
    "                                     padding=2,\n",
    "                                     output_padding=1)\n",
    "        \n",
    "        self.l7 = nn.ConvTranspose2d(in_channels=4*self.latent_channels,\n",
    "                                     out_channels=2*self.latent_channels,\n",
    "                                     kernel_size=self.kernel_size,\n",
    "                                     stride=2,\n",
    "                                     padding=2,\n",
    "                                     output_padding=1)\n",
    "        \n",
    "        self.l8 = nn.ConvTranspose2d(in_channels=3*self.latent_channels,\n",
    "                                     out_channels=self.latent_channels,\n",
    "                                     kernel_size=self.kernel_size,\n",
    "                                     stride=2,\n",
    "                                     padding=2,\n",
    "                                     output_padding=1)\n",
    "\n",
    "        self.last_multiplier = nn.Conv2d(in_channels=self.in_channels+self.latent_channels,\n",
    "                                         out_channels=self.out_channels,\n",
    "                                         kernel_size=1,\n",
    "                                         stride=1,\n",
    "                                         padding=0)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self, tensor):\n",
    "        \n",
    "        h1 = self.activation(self.l1(tensor))\n",
    "        h2 = self.activation(self.l2(h1))\n",
    "        h3 = self.activation(self.l3(h2))\n",
    "        h4 = self.activation(self.l4(h3))\n",
    "        \n",
    "        h5 = self.activation(self.l5(h4))\n",
    "        h5 = torch.cat([h3, h5], dim=1)\n",
    "        \n",
    "        h6 = self.activation(self.l6(h5))\n",
    "        h6 = torch.cat([h2, h6], dim=1)\n",
    "        \n",
    "        h7 = self.activation(self.l7(h6))\n",
    "        h7 = torch.cat([h1, h7], dim=1)\n",
    "        \n",
    "        h8 = self.activation(self.l8(h7))\n",
    "        h8 = torch.cat([tensor, h8], dim=1)\n",
    "        \n",
    "        output = self.last_multiplier(h8)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f98f2d7-fef8-4bed-86a8-66f477562dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardEnvUpscaleEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, lengthscale):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.lengthscale = nn.Parameter(torch.tensor([lengthscale, lengthscale]))\n",
    "\n",
    "        \n",
    "    def convert_to_fine(self, tensor, lonlat_coarse, lonlat_fine):\n",
    "        \"\"\"\n",
    "        Upscales **tensor** with corresponding coordinates **lonlat_coarse**\n",
    "        to a finer discretisation with coordinates **lonlat_fine**.\n",
    "        \n",
    "        Arguments:\n",
    "        \n",
    "            tensor        : torch.tensor, shape (B, C, K, L)\n",
    "            lonlat_coarse : torch.tensor, shape (K, L, 2)\n",
    "            lonlat_fine   : torch.tensor, shape (N, M, 2)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute differences between grid locations\n",
    "        diff = lonlat_coarse[:, :, None, None, :] - \\\n",
    "               lonlat_fine[None, None, :, :, :]\n",
    "        \n",
    "        # Compute weight matrix\n",
    "        quad = -0.5 * (diff / self.lengthscale[None, None, None, None, :]) ** 2\n",
    "        quad = torch.sum(quad, axis=-1)\n",
    "        exp = torch.exp(quad)\n",
    "        \n",
    "        # Compute refined tensor\n",
    "        tensor = torch.einsum('bckl, klnm -> bcnm', tensor, exp)\n",
    "        \n",
    "        return tensor\n",
    "    \n",
    "        \n",
    "    def forward(self,\n",
    "                lonlat_fine,\n",
    "                elevation_fine,\n",
    "                lonlat_coarse,\n",
    "                reanalysis_coarse):\n",
    "        \n",
    "        # Get number of batches\n",
    "        B = reanalysis_coarse.shape[0]\n",
    "        \n",
    "        # Upscale reanalysis data to match elevation grid\n",
    "        reanalysis_fine = self.convert_to_fine(tensor=reanalysis_coarse,\n",
    "                                               lonlat_coarse=lonlat_coarse,\n",
    "                                               lonlat_fine=lonlat_fine)\n",
    "        \n",
    "        elevation_fine = elevation_fine[None, None, :, :].repeat(B, 1, 1, 1)\n",
    "        \n",
    "        #Concatenate reanalysis and elevation\n",
    "        tensor = torch.cat([reanalysis_fine, elevation_fine], axis=1)\n",
    "        \n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a6a5b2-c7bf-42de-b501-108fcc574e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardEnvDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, lengthscale):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.lengthscale = nn.Parameter(torch.tensor([lengthscale, lengthscale]))\n",
    "        \n",
    "\n",
    "    def forward(self, tensor, lonlat_fine, lonlat_target):\n",
    "        \"\"\"\n",
    "        \n",
    "        Arguments:\n",
    "        \n",
    "            tensor        : torch.tensor, shape (B, C, K, L)\n",
    "            lonlat_fine   : torch.tensor, shape (K, L, 2)\n",
    "            lonlat_target : torch.tensor, shape (N, 2)\n",
    "            \n",
    "        Returns:\n",
    "            tensor        : torch.tensor, shape (B, C, N)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute differences between grid locations\n",
    "        diff = lonlat_fine[:, :, None, :] - \\\n",
    "               lonlat_target[None, None, :, :]\n",
    "        \n",
    "        # Compute weight matrix\n",
    "        quad = -0.5 * (diff / self.lengthscale[None, None, None, :]) ** 2\n",
    "        quad = torch.sum(quad, axis=-1)\n",
    "        exp = torch.exp(quad)\n",
    "        \n",
    "        # Compute refined tensor\n",
    "        tensor = torch.einsum('bckl, kln -> bcn', tensor, exp)\n",
    "        \n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfb8744-f6de-41b9-952c-13093e27b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvUpscaleConvCNP(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.lengthscale = 0.2\n",
    "        self.conv_in_channels = 26\n",
    "        self.conv_latent_channels = 8\n",
    "        self.out_channels = 2\n",
    "        \n",
    "        self.encoder = StandardEnvUpscaleEncoder(lengthscale=self.lengthscale)\n",
    "        \n",
    "        self.cnn = StandardEnvUNet(in_channels=self.conv_in_channels,\n",
    "                                   latent_channels=self.conv_latent_channels,\n",
    "                                   out_channels=self.out_channels)\n",
    "        \n",
    "        self.decoder = StandardEnvDecoder(lengthscale=self.lengthscale)\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        # Pass through encoder\n",
    "        tensor = self.encoder(lonlat_fine=batch['lonlat_fine'],\n",
    "                              elevation_fine=batch['elevation_fine'],\n",
    "                              lonlat_coarse=batch['lonlat_coarse'],\n",
    "                              reanalysis_coarse=batch['reanalysis_coarse'])\n",
    "        \n",
    "        # Pass through CNN\n",
    "        tensor = self.cnn(tensor)\n",
    "        \n",
    "        # Pass through decoder\n",
    "        tensor = self.decoder(tensor,\n",
    "                              lonlat_fine=batch['lonlat_fine'],\n",
    "                              lonlat_target=batch['lonlat_station'])\n",
    "        \n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921c468c-c665-42d3-8bba-e74b781f2c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations_per_epoch = 1\n",
    "batch_size = 16\n",
    "\n",
    "data = Dataloader(lonlat_fine=lonlat_fine,\n",
    "                  lonlat_coarse=lonlat_coarse,\n",
    "                  elevation_fine=elevation_fine,\n",
    "                  reanalysis_coarse=train_reanalysis_coarse,\n",
    "                  lonlat_station=train_lonlat_station,\n",
    "                  temperature_station=train_temperature_station,\n",
    "                  iterations_per_epoch=iterations_per_epoch,\n",
    "                  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06465c60-e7d7-4909-83ed-3ecfc7d1d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "convCNP = EnvUpscaleConvCNP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e3bf01-0fbc-4814-83f3-c418b6b1f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in data:\n",
    "    \n",
    "    tensor = convCNP(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0f699d-8587-4614-8c99-84b47abeb004",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15308f9d-df28-408d-b372-18db1a37473b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-kernelcnp",
   "language": "python",
   "name": "venv-kernelcnp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
