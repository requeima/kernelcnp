{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65884260-b92a-429c-98c3-b1ac86f8812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "from cnp.cnp import GaussianNeuralProcess\n",
    "from cnp.data import LambdaIterator\n",
    "from cnp.cov import MeanFieldCov, InnerProdCov, KvvCov, AddNoNoise, AddHomoNoise\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcab4651-2963-4156-b0c7-4de2258f8b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/scratches/cblgpu07/em626/kernelcnp/kernelcnp/experiments/environmental/data'\n",
    "\n",
    "np_lonlat_fine = np.load(f'{data_root}/x_context_fine.npy')\n",
    "np_lonlat_coarse = np.load(f'{data_root}/x_context_coarse.npy')\n",
    "np_elevation_fine = np.load(f'{data_root}/y_context_fine.npy')\n",
    "\n",
    "np_train_reanalysis_coarse = np.load(f'{data_root}/y_context_coarse_train.npy')\n",
    "np_train_lonlat_station = np.load(f'{data_root}/x_target_train.npy')\n",
    "np_train_temperature_station = np.load(f'{data_root}/y_target_train.npy')\n",
    "\n",
    "np_test_reanalysis_coarse = np.load(f'{data_root}/y_context_coarse_val.npy')\n",
    "np_test_lonlat_station = np.load(f'{data_root}/x_target_val.npy')\n",
    "np_test_temperature_station = np.load(f'{data_root}/y_target_val.npy')\n",
    "\n",
    "lonlat_fine = torch.tensor(np_lonlat_fine).float()\n",
    "lonlat_coarse = torch.tensor(np_lonlat_coarse).float()\n",
    "np_elevation_fine = (np_elevation_fine - np.mean(np_elevation_fine)) / np.std(np_elevation_fine)\n",
    "elevation_fine = torch.tensor(np_elevation_fine).float()\n",
    "\n",
    "idx = torch.randperm(np_train_lonlat_station.shape[0])\n",
    "train_lonlat_station = torch.tensor(np_train_lonlat_station).float()[idx, :][:-1]\n",
    "train_temperature_station = torch.tensor(np_train_temperature_station).float()[:, idx][:, :-1]\n",
    "train_reanalysis_coarse = torch.tensor(np_train_reanalysis_coarse).float()\n",
    "\n",
    "# Compute mean and standard deviation of inputs for normalising\n",
    "train_reanalysis_mean = torch.mean(train_reanalysis_coarse, dim=[0, 2, 3])[None, :, None, None]\n",
    "train_reanalysis_stds = torch.var(train_reanalysis_coarse, dim=[0, 2, 3])[None, :, None, None]**0.5\n",
    "\n",
    "train_reanalysis_coarse = (train_reanalysis_coarse - train_reanalysis_mean) / train_reanalysis_stds\n",
    "\n",
    "# Compute mean and standard deviation of outputs for normalising\n",
    "flat = torch.flatten(train_temperature_station)\n",
    "train_temperature_station_mean = torch.mean(flat[~torch.isnan(flat)])\n",
    "train_temperature_station_std = torch.var(flat[~torch.isnan(flat)])**0.5\n",
    "\n",
    "train_temperature_station = (train_temperature_station - train_temperature_station_mean) / \\\n",
    "                            train_temperature_station_std\n",
    "\n",
    "valid_lonlat_station = torch.tensor(np_train_lonlat_station).float()[idx, :][-1:]\n",
    "valid_temperature_station = torch.tensor(np_train_temperature_station).float()[:, idx][:, -1:]\n",
    "valid_reanalysis_coarse = torch.tensor(np_train_reanalysis_coarse).float()\n",
    "valid_reanalysis_coarse = (valid_reanalysis_coarse - train_reanalysis_mean) / train_reanalysis_stds\n",
    "\n",
    "valid_temperature_station = (valid_temperature_station - train_temperature_station_mean) / \\\n",
    "                            train_temperature_station_std\n",
    "\n",
    "test_lonlat_station = torch.tensor(np_test_lonlat_station).float()\n",
    "test_temperature_station = torch.tensor(np_test_temperature_station).float()\n",
    "test_reanalysis_coarse = torch.tensor(np_test_reanalysis_coarse).float()\n",
    "test_reanalysis_coarse = (test_reanalysis_coarse - train_reanalysis_mean) / train_reanalysis_stds\n",
    "\n",
    "test_temperature_station = (test_temperature_station - train_temperature_station_mean) / \\\n",
    "                            train_temperature_station_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c675859b-e837-42a2-bba9-06b4bf3d5f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lonlat_fine                    torch.Size([1200, 1200, 2])\n",
      "lonlat_coarse                  torch.Size([6, 6, 2])\n",
      "elevation_fine                 torch.Size([1200, 1200]) \n",
      "\n",
      "train_reanalysis_coarse        torch.Size([8766, 25, 6, 6])\n",
      "train_lonlat_station           torch.Size([961, 2])\n",
      "train_temperature_station      torch.Size([8766, 961]) \n",
      "\n",
      "valid_reanalysis_coarse        torch.Size([8766, 25, 6, 6])\n",
      "valid_lonlat_station           torch.Size([1, 2])\n",
      "valid_temperature_station      torch.Size([8766, 1]) \n",
      "\n",
      "test_reanalysis_coarse         torch.Size([2192, 25, 6, 6])\n",
      "test_lonlat_station            torch.Size([24, 2])\n",
      "test_temperature_station       torch.Size([11688, 24])\n"
     ]
    }
   ],
   "source": [
    "print('lonlat_fine'.ljust(30), lonlat_fine.shape)\n",
    "print('lonlat_coarse'.ljust(30), lonlat_coarse.shape)\n",
    "print('elevation_fine'.ljust(30), elevation_fine.shape, '\\n')\n",
    "\n",
    "print('train_reanalysis_coarse'.ljust(30), train_reanalysis_coarse.shape)\n",
    "print('train_lonlat_station'.ljust(30), train_lonlat_station.shape)\n",
    "print('train_temperature_station'.ljust(30), train_temperature_station.shape, '\\n')\n",
    "\n",
    "print('valid_reanalysis_coarse'.ljust(30), valid_reanalysis_coarse.shape)\n",
    "print('valid_lonlat_station'.ljust(30), valid_lonlat_station.shape)\n",
    "print('valid_temperature_station'.ljust(30), valid_temperature_station.shape, '\\n')\n",
    "\n",
    "print('test_reanalysis_coarse'.ljust(30), test_reanalysis_coarse.shape)\n",
    "print('test_lonlat_station'.ljust(30), test_lonlat_station.shape)\n",
    "print('test_temperature_station'.ljust(30), test_temperature_station.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "189e6dbf-92ef-462b-a2d8-72949f24a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elevation(lonlat_fine, lonlat_station, elevation_fine):\n",
    "    \n",
    "    diff = lonlat_fine[:, :, None, :] - lonlat_station[None, None, :, :]\n",
    "    dist = torch.sum(diff**2, dim=-1)**0.5\n",
    "    dist = -torch.permute(dist, (2, 0, 1))\n",
    "    \n",
    "    n = torch.tensor(dist.shape[0])\n",
    "    d = torch.tensor(dist.shape[1])\n",
    "    m = dist.view(n, -1).argmax(1)\n",
    "    idx = torch.cat(((m // d).view(-1, 1), (m % d).view(-1, 1)), dim=1)\n",
    "    \n",
    "    return torch.tensor([elevation_fine[i, j] for i, j in idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e5e0978-49cc-4997-80a2-21067220a428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratches/cblgpu07/em626/kernelcnp/venv-kernelcnp/lib/python3.6/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    }
   ],
   "source": [
    "train_station_elevation = get_elevation(lonlat_fine=lonlat_fine,\n",
    "                                        lonlat_station=train_lonlat_station,\n",
    "                                        elevation_fine=elevation_fine)\n",
    "train_station_elevation = train_station_elevation.float()\n",
    "\n",
    "valid_station_elevation = get_elevation(lonlat_fine=lonlat_fine,\n",
    "                                        lonlat_station=valid_lonlat_station,\n",
    "                                        elevation_fine=elevation_fine)\n",
    "valid_station_elevation = valid_station_elevation.float()\n",
    "\n",
    "test_station_elevation = get_elevation(lonlat_fine=lonlat_fine,\n",
    "                                       lonlat_station=test_lonlat_station,\n",
    "                                       elevation_fine=elevation_fine)\n",
    "test_station_elevation = test_station_elevation.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bab440a-43a3-414c-a3a5-a5fc5ee0f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 lonlat_fine,\n",
    "                 lonlat_coarse,\n",
    "                 elevation_fine,\n",
    "                 reanalysis_coarse,\n",
    "                 lonlat_station,\n",
    "                 elevation_station,\n",
    "                 temperature_station,\n",
    "                 iterations_per_epoch,\n",
    "                 max_num_target,\n",
    "                 batch_size,\n",
    "                 device):\n",
    "        \n",
    "        # Set data tensors\n",
    "        self.lonlat_fine = lonlat_fine\n",
    "        self.lonlat_coarse = lonlat_coarse\n",
    "        self.elevation_fine = elevation_fine\n",
    "        self.reanalysis_coarse = reanalysis_coarse\n",
    "        self.lonlat_station = lonlat_station\n",
    "        self.elevation_station = elevation_station\n",
    "        self.temperature_station = temperature_station\n",
    "        \n",
    "        # Set dataloader parameters\n",
    "        self.iterations_per_epoch = iterations_per_epoch\n",
    "        self.max_num_target = max_num_target\n",
    "        self.num_datasets = self.reanalysis_coarse.shape[0]\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        \n",
    "        \n",
    "    def generate_batch(self):\n",
    "        \n",
    "        # Draw batch indices at random - these are time indices\n",
    "        idx1 = torch.randperm(self.num_datasets)[:batch_size]\n",
    "        \n",
    "        batch_reanalysis_coarse = self.reanalysis_coarse[idx1]\n",
    "        batch_temperature_station = self.temperature_station[idx1]\n",
    "        \n",
    "        # Keep stations which have no nan values\n",
    "        nan_mask = torch.isnan(torch.sum(batch_temperature_station, dim=0))\n",
    "        \n",
    "        batch_lonlat_station = self.lonlat_station[~nan_mask, :]\n",
    "        batch_elevation_station = self.elevation_station[~nan_mask]\n",
    "        batch_temperature_station = batch_temperature_station[:, ~nan_mask]\n",
    "        \n",
    "        # From the non-nan stations, pick **num_target** at random\n",
    "        num_target = min(max_num_target, nan_mask.shape[0])\n",
    "        idx2 = torch.randperm(batch_lonlat_station.shape[0])[:num_target]\n",
    "        \n",
    "        batch_lonlat_station = batch_lonlat_station[idx2, :]\n",
    "        batch_elevation_station = batch_elevation_station[idx2]\n",
    "        batch_temperature_station = batch_temperature_station[:, idx2]\n",
    "        \n",
    "        a = torch.cuda.memory_allocated('cuda:1')\n",
    "        if False: print(f'Memory usage (before loading):'.ljust(50) + f'{a}')\n",
    "        \n",
    "        batch = {'lonlat_fine'         : self.lonlat_fine.to(self.device),\n",
    "                 'lonlat_coarse'       : self.lonlat_coarse.to(self.device),\n",
    "                 'elevation_fine'      : self.elevation_fine.to(self.device),\n",
    "                 'reanalysis_coarse'   : batch_reanalysis_coarse.to(self.device),\n",
    "                 'lonlat_station'      : batch_lonlat_station.to(self.device),\n",
    "                 'elevation_station'   : batch_elevation_station.to(self.device),\n",
    "                 'temperature_station' : batch_temperature_station.to(self.device)}\n",
    "        \n",
    "        \n",
    "        a = torch.cuda.memory_allocated('cuda:1')\n",
    "        if False: print(f'Memory usage (after loading):'.ljust(50) + f'{a}')\n",
    "        \n",
    "        return batch\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return LambdaIterator(lambda: self.generate_batch(), self.iterations_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe8b6faa-bf68-4246-8bae-64053e34336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 latent_channels,\n",
    "                 out_channels):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.latent_channels = latent_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = 3\n",
    "        self.padding = (self.kernel_size - 1) // 2\n",
    "        \n",
    "        self.l1 = nn.Conv2d(in_channels=self.in_channels,\n",
    "                            out_channels=self.latent_channels,\n",
    "                            kernel_size=self.kernel_size,\n",
    "                            padding=self.padding,\n",
    "                            stride=1)\n",
    "        \n",
    "        self.l2 = nn.Conv2d(in_channels=self.latent_channels,\n",
    "                            out_channels=self.latent_channels,\n",
    "                            kernel_size=self.kernel_size,\n",
    "                            padding=self.padding,\n",
    "                            stride=1)\n",
    "        \n",
    "        self.l3 = nn.Conv2d(in_channels=self.latent_channels,\n",
    "                            out_channels=self.latent_channels,\n",
    "                            kernel_size=self.kernel_size,\n",
    "                            padding=self.padding,\n",
    "                            stride=1)\n",
    "        \n",
    "        self.l4 = nn.Conv2d(in_channels=self.latent_channels,\n",
    "                            out_channels=self.latent_channels,\n",
    "                            kernel_size=self.kernel_size,\n",
    "                            padding=self.padding,\n",
    "                            stride=1)\n",
    "\n",
    "        self.l5 = nn.Conv2d(in_channels=self.latent_channels,\n",
    "                            out_channels=self.out_channels,\n",
    "                            kernel_size=1,\n",
    "                            stride=1,\n",
    "                            padding=0)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self, tensor):\n",
    "        \n",
    "        tensor = self.activation(self.l1(tensor))\n",
    "        \n",
    "        tensor = self.activation(self.l2(tensor)) + tensor\n",
    "        tensor = self.activation(self.l3(tensor)) + tensor\n",
    "        tensor = self.activation(self.l4(tensor)) + tensor\n",
    "        \n",
    "        tensor = self.l5(tensor)\n",
    "        \n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f98f2d7-fef8-4bed-86a8-66f477562dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardResNetEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_in_channels = 25\n",
    "        self.conv_latent_channels = 128\n",
    "        self.conv_out_channels = 5\n",
    "        \n",
    "        self.cnn = StandardResNet(in_channels=self.conv_in_channels,\n",
    "                                  latent_channels=self.conv_latent_channels,\n",
    "                                  out_channels=self.conv_out_channels)\n",
    "    \n",
    "        \n",
    "    def forward(self, reanalysis_coarse):\n",
    "        return self.cnn(reanalysis_coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9a6a5b2-c7bf-42de-b501-108fcc574e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardEnvDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, lengthscale, out_channels):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.log_lengthscale = nn.Parameter(torch.tensor([np.log(lengthscale),\n",
    "                                                          np.log(lengthscale)]).float())\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        self.l1 = nn.Linear(in_features=6,\n",
    "                            out_features=64,\n",
    "                            bias=True)\n",
    "\n",
    "        self.l2 = nn.Linear(in_features=64,\n",
    "                            out_features=64,\n",
    "                            bias=True)\n",
    "\n",
    "        self.l3 = nn.Linear(in_features=64,\n",
    "                            out_features=64,\n",
    "                            bias=True)\n",
    "\n",
    "        self.l4 = nn.Linear(in_features=64,\n",
    "                            out_features=self.out_channels,\n",
    "                            bias=True)\n",
    "        \n",
    "    @property\n",
    "    def lengthscale(self):\n",
    "        return torch.exp(self.log_lengthscale)\n",
    "        \n",
    "\n",
    "    def forward(self, tensor, elevation_station, lonlat_coarse, lonlat_target):\n",
    "        \"\"\"\n",
    "        \n",
    "        Arguments:\n",
    "            tensor        : torch.tensor, shape (B, C1, K, L)\n",
    "            lonlat_fine   : torch.tensor, shape (K, L, 2)\n",
    "            lonlat_target : torch.tensor, shape (N, 2)\n",
    "            \n",
    "        Returns:\n",
    "            tensor        : torch.tensor, shape (B, C2, N)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute differences between grid locations\n",
    "        diff = lonlat_coarse[:, :, None, :] - \\\n",
    "               lonlat_target[None, None, :, :]\n",
    "        \n",
    "        # Compute weight matrix\n",
    "        quad = -0.5 * (diff / self.lengthscale[None, None, None, :]) ** 2\n",
    "        quad = torch.sum(quad, axis=-1)\n",
    "        \n",
    "        exp = torch.exp(quad)\n",
    "        exp = exp / torch.sum(exp, dim=[0, 1])[None, None, :]\n",
    "        \n",
    "        # Compute refined tensor\n",
    "        tensor = torch.einsum('bckl, kln -> bcn', tensor, exp)\n",
    "        \n",
    "        elevation_station = elevation_station[None, None, :].repeat(tensor.shape[0], 1, 1)\n",
    "        tensor = torch.cat([tensor, elevation_station], dim=1)\n",
    "        \n",
    "        tensor = torch.permute(tensor, (0, 2, 1))\n",
    "        \n",
    "        tensor = self.l1(tensor)\n",
    "        tensor = self.activation(tensor)\n",
    "        \n",
    "        tensor = self.l2(tensor)\n",
    "        tensor = self.activation(tensor)\n",
    "        \n",
    "        tensor = self.l3(tensor)\n",
    "        tensor = self.activation(tensor)\n",
    "        \n",
    "        tensor = self.l4(tensor)\n",
    "        \n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdfb8744-f6de-41b9-952c-13093e27b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvResNetConvGNP(GaussianNeuralProcess):\n",
    "    \n",
    "    def __init__(self, covariance, add_noise):\n",
    "        \n",
    "        self.output_dim = 1\n",
    "        self.decoder_lengthscale = 1.\n",
    "        \n",
    "        # Construct the convolutional decoder\n",
    "        decoder_out_channels = self.output_dim          + \\\n",
    "                               covariance.num_basis_dim + \\\n",
    "                               covariance.extra_cov_dim + \\\n",
    "                               add_noise.extra_noise_dim\n",
    "        \n",
    "        encoder = StandardResNetEncoder()\n",
    "        \n",
    "        decoder = StandardEnvDecoder(lengthscale=self.decoder_lengthscale,\n",
    "                                     out_channels=decoder_out_channels)\n",
    "\n",
    "        super().__init__(encoder=encoder,\n",
    "                         decoder=decoder,\n",
    "                         covariance=covariance,\n",
    "                         add_noise=add_noise)\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        # Pass through encoder\n",
    "        tensor = self.encoder(reanalysis_coarse=batch['reanalysis_coarse'])\n",
    "        \n",
    "        # Pass through decoder\n",
    "        tensor = self.decoder(tensor,\n",
    "                              elevation_station=batch['elevation_station'],\n",
    "                              lonlat_coarse=batch['lonlat_coarse'],\n",
    "                              lonlat_target=batch['lonlat_station'])\n",
    "        \n",
    "        # Produce mean\n",
    "        mean = tensor[..., 0:1]\n",
    "        \n",
    "        # Produce cov\n",
    "        embedding = tensor[..., 1:]\n",
    "        cov = self.covariance(embedding)\n",
    "        cov_plus_noise = self.add_noise(cov, embedding)\n",
    "        \n",
    "        return mean, cov, cov_plus_noise\n",
    "\n",
    "    \n",
    "    def loss(self, batch):\n",
    "\n",
    "        y_mean, _, y_cov = self.forward(batch)\n",
    "\n",
    "        y_mean = y_mean.double()\n",
    "        y_cov = y_cov.double()\n",
    "        y_target = batch['temperature_station'].double()\n",
    "\n",
    "        jitter = 1e-3 * torch.eye(y_cov.shape[-1], device=y_cov.device).double()\n",
    "        y_cov = y_cov + jitter[None, :, :]\n",
    "        \n",
    "        mae = torch.mean(torch.abs(y_mean[:, :, 0] - y_target))\n",
    "        \n",
    "        dist = MultivariateNormal(loc=y_mean[:, :, 0], covariance_matrix=y_cov)\n",
    "        nll = - torch.mean(dist.log_prob(y_target.double()))\n",
    "\n",
    "        return nll.float(), mae.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a98c5cae-90ac-4b38-ac39-607577d52b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "921c468c-c665-42d3-8bba-e74b781f2c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations_per_epoch = 5000\n",
    "batch_size = 64\n",
    "max_num_target = 128\n",
    "\n",
    "test_batch_size = 64\n",
    "test_max_num_target = 64\n",
    "\n",
    "train_data = Dataloader(lonlat_fine=lonlat_fine,\n",
    "                        lonlat_coarse=lonlat_coarse,\n",
    "                        elevation_fine=elevation_fine,\n",
    "                        reanalysis_coarse=train_reanalysis_coarse,\n",
    "                        lonlat_station=train_lonlat_station,\n",
    "                        elevation_station=train_station_elevation,\n",
    "                        temperature_station=train_temperature_station,\n",
    "                        iterations_per_epoch=iterations_per_epoch,\n",
    "                        max_num_target=max_num_target,\n",
    "                        batch_size=batch_size,\n",
    "                        device=device)\n",
    "\n",
    "valid_data = Dataloader(lonlat_fine=lonlat_fine,\n",
    "                        lonlat_coarse=lonlat_coarse,\n",
    "                        elevation_fine=elevation_fine,\n",
    "                        reanalysis_coarse=valid_reanalysis_coarse,\n",
    "                        lonlat_station=valid_lonlat_station,\n",
    "                        elevation_station=valid_station_elevation,\n",
    "                        temperature_station=valid_temperature_station,\n",
    "                        iterations_per_epoch=iterations_per_epoch,\n",
    "                        max_num_target=max_num_target,\n",
    "                        batch_size=batch_size,\n",
    "                        device=device)\n",
    "\n",
    "test_data = Dataloader(lonlat_fine=lonlat_fine,\n",
    "                       lonlat_coarse=lonlat_coarse,\n",
    "                       elevation_fine=elevation_fine,\n",
    "                       reanalysis_coarse=test_reanalysis_coarse,\n",
    "                       lonlat_station=test_lonlat_station,\n",
    "                       elevation_station=test_station_elevation,\n",
    "                       temperature_station=test_temperature_station,\n",
    "                       iterations_per_epoch=iterations_per_epoch,\n",
    "                       max_num_target=test_max_num_target,\n",
    "                       batch_size=test_batch_size,\n",
    "                       device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef86bc87-8f44-4c36-bc90-10eeb8cfe20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 179.98, 0.00, 39.24 MAE: 7.50, 0.00, 8.74 Decoder scale: 1.00, 1.00 \n",
      "Loss: 129.89, 0.00, 29.46 MAE: 7.50, 0.00, 7.66 Decoder scale: 1.00, 1.00 \n",
      "Loss: 129.48, 0.00, 30.04 MAE: 7.49, 0.00, 8.39 Decoder scale: 1.00, 1.00 \n",
      "Loss: 126.39, 0.00, 27.99 MAE: 6.66, 0.00, 7.45 Decoder scale: 1.00, 1.00 \n",
      "Loss: 125.50, 0.00, 29.27 MAE: 7.62, 0.00, 8.50 Decoder scale: 1.00, 1.00 \n",
      "Loss: 125.09, 0.00, 28.62 MAE: 6.75, 0.00, 7.93 Decoder scale: 1.01, 1.00 \n",
      "Loss: 124.50, 0.00, 28.58 MAE: 6.58, 0.00, 8.39 Decoder scale: 1.01, 1.01 \n",
      "Loss: 124.40, 0.00, 28.12 MAE: 6.61, 0.00, 7.90 Decoder scale: 1.01, 1.01 \n",
      "Loss: 124.00, 0.00, 27.53 MAE: 7.13, 0.00, 7.33 Decoder scale: 1.01, 1.01 \n",
      "Loss: 123.20, 0.00, 27.63 MAE: 7.32, 0.00, 7.46 Decoder scale: 1.01, 1.01 \n",
      "Loss: 123.70, 0.00, 27.86 MAE: 7.00, 0.00, 8.36 Decoder scale: 1.01, 1.01 \n",
      "Loss: 123.49, 0.00, 27.48 MAE: 6.89, 0.00, 7.85 Decoder scale: 1.01, 1.01 \n",
      "Loss: 122.44, 0.00, 27.43 MAE: 6.68, 0.00, 8.11 Decoder scale: 1.01, 1.01 \n",
      "Loss: 122.53, 0.00, 27.28 MAE: 7.29, 0.00, 7.79 Decoder scale: 1.01, 1.01 \n",
      "Loss: 121.57, 0.00, 27.14 MAE: 6.01, 0.00, 7.97 Decoder scale: 1.02, 1.01 \n",
      "Loss: 121.50, 0.00, 26.98 MAE: 6.49, 0.00, 7.73 Decoder scale: 1.02, 1.01 \n",
      "Loss: 122.10, 0.00, 26.92 MAE: 6.81, 0.00, 7.64 Decoder scale: 1.02, 1.01 \n",
      "Loss: 121.29, 0.00, 26.97 MAE: 6.04, 0.00, 7.95 Decoder scale: 1.02, 1.01 \n",
      "Loss: 121.33, 0.00, 26.94 MAE: 5.91, 0.00, 7.70 Decoder scale: 1.02, 1.01 \n",
      "Loss: 120.72, 0.00, 26.61 MAE: 5.93, 0.00, 7.41 Decoder scale: 1.02, 1.01 \n",
      "Loss: 120.68, 0.00, 26.60 MAE: 5.24, 0.00, 6.84 Decoder scale: 1.02, 1.01 \n",
      "Loss: 120.71, 0.00, 26.58 MAE: 5.99, 0.00, 6.78 Decoder scale: 1.02, 1.01 \n",
      "Loss: 120.06, 0.00, 26.42 MAE: 4.71, 0.00, 6.79 Decoder scale: 1.02, 1.01 \n",
      "Loss: 119.75, 0.00, 26.15 MAE: 4.91, 0.00, 6.31 Decoder scale: 1.02, 1.01 \n",
      "Loss: 119.21, 0.00, 25.98 MAE: 4.15, 0.00, 5.61 Decoder scale: 1.02, 1.01 \n",
      "Loss: 119.29, 0.00, 26.35 MAE: 4.17, 0.00, 6.26 Decoder scale: 1.02, 1.01 \n",
      "Loss: 118.74, 0.00, 23.80 MAE: 3.05, 0.00, 4.77 Decoder scale: 1.02, 1.01 \n",
      "Loss: 117.95, 0.00, 26.04 MAE: 1.92, 0.00, 4.69 Decoder scale: 1.02, 1.01 \n",
      "Loss: 116.99, 0.00, 27.38 MAE: 1.50, 0.00, 5.09 Decoder scale: 1.02, 1.01 \n",
      "Loss: 116.29, 0.00, 28.61 MAE: 1.34, 0.00, 5.53 Decoder scale: 1.02, 1.00 \n",
      "Loss: 116.05, 0.00, 28.11 MAE: 1.19, 0.00, 5.23 Decoder scale: 1.02, 1.00 \n",
      "Loss: 116.11, 0.00, 28.83 MAE: 1.25, 0.00, 5.36 Decoder scale: 1.02, 1.00 \n",
      "Loss: 116.04, 0.00, 27.45 MAE: 1.21, 0.00, 4.75 Decoder scale: 1.02, 1.00 \n",
      "Loss: 115.70, 0.00, 28.08 MAE: 1.21, 0.00, 5.05 Decoder scale: 1.02, 1.00 \n",
      "Loss: 115.53, 0.00, 27.02 MAE: 1.19, 0.00, 4.67 Decoder scale: 1.02, 1.00 \n",
      "Loss: 115.01, 0.00, 26.42 MAE: 1.09, 0.00, 4.44 Decoder scale: 1.02, 1.00 \n",
      "Loss: 115.30, 0.00, 27.10 MAE: 1.19, 0.00, 4.67 Decoder scale: 1.02, 1.00 \n",
      "Loss: 114.86, 0.00, 28.94 MAE: 1.13, 0.00, 5.31 Decoder scale: 1.02, 1.00 \n",
      "Loss: 114.89, 0.00, 26.23 MAE: 1.17, 0.00, 4.41 Decoder scale: 1.02, 1.00 \n",
      "Loss: 115.04, 0.00, 27.46 MAE: 1.20, 0.00, 4.99 Decoder scale: 1.02, 1.00 \n",
      "Loss: 114.92, 0.00, 26.23 MAE: 1.22, 0.00, 4.34 Decoder scale: 1.02, 1.00 \n",
      "Loss: 114.68, 0.00, 29.70 MAE: 1.20, 0.00, 5.57 Decoder scale: 1.01, 1.00 \n",
      "Loss: 114.37, 0.00, 29.31 MAE: 1.13, 0.00, 5.47 Decoder scale: 1.01, 1.00 \n",
      "Loss: 114.23, 0.00, 27.42 MAE: 1.16, 0.00, 4.76 Decoder scale: 1.01, 1.00 \n",
      "Loss: 114.19, 0.00, 28.24 MAE: 1.14, 0.00, 5.26 Decoder scale: 1.01, 1.00 \n",
      "Loss: 114.12, 0.00, 27.46 MAE: 1.14, 0.00, 4.89 Decoder scale: 1.01, 1.00 \n",
      "Loss: 113.61, 0.00, 28.38 MAE: 1.09, 0.00, 5.29 Decoder scale: 1.01, 1.00 \n",
      "Loss: 113.47, 0.00, 27.80 MAE: 1.06, 0.00, 4.85 Decoder scale: 1.01, 1.00 \n",
      "Loss: 113.84, 0.00, 28.22 MAE: 1.19, 0.00, 5.02 Decoder scale: 1.01, 1.00 \n",
      "Loss: 113.35, 0.00, 26.41 MAE: 1.11, 0.00, 4.41 Decoder scale: 1.01, 0.99 \n",
      "Loss: 113.58, 0.00, 25.50 MAE: 1.20, 0.00, 4.58 Decoder scale: 1.01, 0.99 \n",
      "Loss: 113.01, 0.00, 26.47 MAE: 1.11, 0.00, 4.53 Decoder scale: 1.01, 0.99 \n",
      "Loss: 113.38, 0.00, 29.09 MAE: 1.21, 0.00, 5.43 Decoder scale: 1.01, 0.99 \n",
      "Loss: 112.99, 0.00, 28.86 MAE: 1.13, 0.00, 5.32 Decoder scale: 1.01, 0.99 \n",
      "Loss: 112.62, 0.00, 27.07 MAE: 1.08, 0.00, 4.78 Decoder scale: 1.01, 0.99 \n",
      "Loss: 113.03, 0.00, 27.94 MAE: 1.21, 0.00, 5.22 Decoder scale: 1.01, 0.99 \n",
      "Loss: 112.74, 0.00, 27.11 MAE: 1.15, 0.00, 4.93 Decoder scale: 1.01, 0.99 \n",
      "Loss: 112.30, 0.00, 27.38 MAE: 1.09, 0.00, 4.92 Decoder scale: 1.01, 0.99 \n",
      "Loss: 112.01, 0.00, 27.46 MAE: 1.07, 0.00, 5.07 Decoder scale: 1.01, 0.99 \n",
      "Loss: 112.48, 0.00, 27.07 MAE: 1.22, 0.00, 4.87 Decoder scale: 1.01, 0.99 \n",
      "Loss: 111.64, 0.00, 26.91 MAE: 1.01, 0.00, 4.76 Decoder scale: 1.01, 0.99 \n",
      "Loss: 111.55, 0.00, 28.77 MAE: 1.04, 0.00, 5.33 Decoder scale: 1.01, 0.99 \n",
      "Loss: 111.58, 0.00, 27.38 MAE: 1.07, 0.00, 4.80 Decoder scale: 1.01, 0.99 \n",
      "Loss: 111.73, 0.00, 29.13 MAE: 1.12, 0.00, 5.61 Decoder scale: 1.01, 0.99 \n",
      "Loss: 111.55, 0.00, 27.13 MAE: 1.15, 0.00, 4.84 Decoder scale: 1.01, 0.99 \n",
      "Loss: 111.66, 0.00, 26.23 MAE: 1.17, 0.00, 4.49 Decoder scale: 1.01, 0.99 \n",
      "Loss: 111.93, 0.00, 27.46 MAE: 1.26, 0.00, 5.05 Decoder scale: 1.01, 0.99 \n",
      "Loss: 111.27, 0.00, 25.95 MAE: 1.15, 0.00, 4.43 Decoder scale: 1.01, 0.99 \n",
      "Loss: 110.73, 0.00, 27.85 MAE: 1.06, 0.00, 4.98 Decoder scale: 1.01, 0.99 \n",
      "Loss: 110.82, 0.00, 25.56 MAE: 1.10, 0.00, 4.57 Decoder scale: 1.01, 0.99 \n",
      "Loss: 110.70, 0.00, 26.35 MAE: 1.08, 0.00, 4.53 Decoder scale: 1.01, 0.99 \n",
      "Loss: 110.64, 0.00, 27.55 MAE: 1.09, 0.00, 4.93 Decoder scale: 1.00, 0.99 \n",
      "Loss: 110.11, 0.00, 26.94 MAE: 0.99, 0.00, 4.73 Decoder scale: 1.00, 0.99 \n",
      "Loss: 110.33, 0.00, 26.65 MAE: 1.11, 0.00, 4.46 Decoder scale: 1.00, 0.99 \n",
      "Loss: 110.60, 0.00, 27.45 MAE: 1.15, 0.00, 5.02 Decoder scale: 1.00, 0.99 \n",
      "Loss: 110.30, 0.00, 28.51 MAE: 1.12, 0.00, 5.27 Decoder scale: 1.00, 0.99 \n",
      "Loss: 110.12, 0.00, 27.91 MAE: 1.13, 0.00, 5.24 Decoder scale: 1.00, 0.99 \n",
      "Loss: 110.04, 0.00, 26.72 MAE: 1.13, 0.00, 4.69 Decoder scale: 1.00, 0.99 \n",
      "Loss: 109.28, 0.00, 26.65 MAE: 1.00, 0.00, 4.60 Decoder scale: 1.00, 0.99 \n",
      "Loss: 109.34, 0.00, 27.71 MAE: 1.04, 0.00, 5.01 Decoder scale: 1.00, 0.99 \n",
      "Loss: 109.03, 0.00, 27.06 MAE: 1.00, 0.00, 4.84 Decoder scale: 1.00, 0.99 \n",
      "Loss: 109.25, 0.00, 27.29 MAE: 1.09, 0.00, 4.89 Decoder scale: 1.00, 0.99 \n",
      "Loss: 109.51, 0.00, 28.71 MAE: 1.16, 0.00, 5.47 Decoder scale: 1.00, 0.99 \n",
      "Loss: 108.83, 0.00, 27.86 MAE: 1.02, 0.00, 5.10 Decoder scale: 1.00, 0.99 \n",
      "Loss: 108.67, 0.00, 26.94 MAE: 1.03, 0.00, 4.96 Decoder scale: 1.00, 0.99 \n",
      "Loss: 108.66, 0.00, 26.44 MAE: 1.08, 0.00, 4.65 Decoder scale: 1.00, 0.99 \n",
      "Loss: 108.62, 0.00, 26.96 MAE: 1.10, 0.00, 5.00 Decoder scale: 1.00, 0.99 \n",
      "Loss: 108.33, 0.00, 28.76 MAE: 1.04, 0.00, 5.36 Decoder scale: 1.00, 0.99 \n",
      "Loss: 108.19, 0.00, 26.48 MAE: 1.04, 0.00, 4.62 Decoder scale: 1.00, 0.99 \n",
      "Loss: 107.82, 0.00, 25.22 MAE: 0.99, 0.00, 5.03 Decoder scale: 1.00, 0.99 \n",
      "Loss: 108.11, 0.00, 27.91 MAE: 1.08, 0.00, 5.25 Decoder scale: 1.00, 0.99 \n",
      "Loss: 108.00, 0.00, 26.95 MAE: 1.07, 0.00, 4.86 Decoder scale: 1.00, 0.99 \n",
      "Loss: 108.00, 0.00, 27.01 MAE: 1.10, 0.00, 4.86 Decoder scale: 1.00, 0.99 \n",
      "Loss: 107.58, 0.00, 28.94 MAE: 1.05, 0.00, 5.46 Decoder scale: 0.99, 0.99 \n",
      "Loss: 107.80, 0.00, 26.02 MAE: 1.13, 0.00, 4.58 Decoder scale: 0.99, 0.99 \n",
      "Loss: 107.64, 0.00, 27.22 MAE: 1.11, 0.00, 4.99 Decoder scale: 0.99, 0.99 \n",
      "Loss: 107.17, 0.00, 30.05 MAE: 1.01, 0.00, 5.72 Decoder scale: 0.99, 0.99 \n",
      "Loss: 107.32, 0.00, 26.56 MAE: 1.09, 0.00, 4.77 Decoder scale: 0.99, 0.99 \n",
      "Loss: 107.11, 0.00, 25.67 MAE: 1.06, 0.00, 4.99 Decoder scale: 0.99, 0.99 \n",
      "Loss: 107.18, 0.00, 28.44 MAE: 1.09, 0.00, 5.36 Decoder scale: 0.99, 0.99 \n",
      "Loss: 106.94, 0.00, 26.89 MAE: 1.09, 0.00, 4.90 Decoder scale: 0.99, 0.99 \n",
      "Loss: 106.83, 0.00, 26.14 MAE: 1.11, 0.00, 4.55 Decoder scale: 0.99, 0.99 \n",
      "Loss: 106.62, 0.00, 26.70 MAE: 1.07, 0.00, 4.79 Decoder scale: 0.99, 0.99 \n",
      "Loss: 106.72, 0.00, 27.30 MAE: 1.13, 0.00, 4.96 Decoder scale: 0.99, 0.99 \n",
      "Loss: 106.33, 0.00, 26.95 MAE: 1.05, 0.00, 4.84 Decoder scale: 0.99, 0.99 \n",
      "Loss: 106.08, 0.00, 27.03 MAE: 1.03, 0.00, 4.93 Decoder scale: 0.99, 0.99 \n",
      "Loss: 106.06, 0.00, 26.18 MAE: 1.03, 0.00, 4.73 Decoder scale: 0.99, 0.99 \n",
      "Loss: 106.16, 0.00, 27.41 MAE: 1.10, 0.00, 5.07 Decoder scale: 0.99, 0.99 \n",
      "Loss: 105.66, 0.00, 25.30 MAE: 1.04, 0.00, 4.44 Decoder scale: 0.99, 0.99 \n",
      "Loss: 105.95, 0.00, 25.72 MAE: 1.12, 0.00, 4.45 Decoder scale: 0.98, 0.99 \n",
      "Loss: 105.75, 0.00, 27.64 MAE: 1.09, 0.00, 5.04 Decoder scale: 0.98, 0.99 \n",
      "Loss: 105.29, 0.00, 26.28 MAE: 1.03, 0.00, 4.76 Decoder scale: 0.98, 0.99 \n",
      "Loss: 105.18, 0.00, 26.50 MAE: 1.04, 0.00, 4.71 Decoder scale: 0.98, 0.99 \n",
      "Loss: 105.20, 0.00, 26.22 MAE: 1.07, 0.00, 4.63 Decoder scale: 0.98, 0.99 \n",
      "Loss: 105.02, 0.00, 26.11 MAE: 1.05, 0.00, 4.67 Decoder scale: 0.98, 0.99 \n",
      "Loss: 104.80, 0.00, 26.57 MAE: 1.02, 0.00, 4.81 Decoder scale: 0.98, 0.99 \n",
      "Loss: 104.86, 0.00, 27.28 MAE: 1.07, 0.00, 5.16 Decoder scale: 0.98, 0.99 \n",
      "Loss: 104.41, 0.00, 26.17 MAE: 1.01, 0.00, 4.62 Decoder scale: 0.98, 0.99 \n",
      "Loss: 104.94, 0.00, 25.27 MAE: 1.14, 0.00, 4.31 Decoder scale: 0.98, 0.99 \n",
      "Loss: 105.04, 0.00, 28.19 MAE: 1.15, 0.00, 5.35 Decoder scale: 0.98, 0.99 \n",
      "Loss: 104.28, 0.00, 27.37 MAE: 1.04, 0.00, 5.07 Decoder scale: 0.98, 0.99 \n",
      "Loss: 104.48, 0.00, 26.46 MAE: 1.13, 0.00, 4.86 Decoder scale: 0.98, 0.99 \n",
      "Loss: 103.93, 0.00, 27.13 MAE: 1.03, 0.00, 4.97 Decoder scale: 0.98, 0.99 \n",
      "Loss: 103.95, 0.00, 27.98 MAE: 1.06, 0.00, 5.23 Decoder scale: 0.98, 0.99 \n",
      "Loss: 103.66, 0.00, 26.40 MAE: 1.00, 0.00, 4.77 Decoder scale: 0.98, 0.99 \n",
      "Loss: 103.34, 0.00, 25.28 MAE: 0.99, 0.00, 4.28 Decoder scale: 0.97, 0.99 \n",
      "Loss: 103.38, 0.00, 25.77 MAE: 1.02, 0.00, 4.61 Decoder scale: 0.97, 0.99 \n",
      "Loss: 103.25, 0.00, 27.65 MAE: 1.02, 0.00, 5.12 Decoder scale: 0.97, 0.99 \n",
      "Loss: 103.05, 0.00, 26.12 MAE: 1.01, 0.00, 4.65 Decoder scale: 0.97, 0.99 \n",
      "Loss: 103.36, 0.00, 25.80 MAE: 1.04, 0.00, 4.64 Decoder scale: 0.97, 0.99 \n",
      "Loss: 102.94, 0.00, 28.22 MAE: 1.04, 0.00, 5.35 Decoder scale: 0.97, 0.99 \n",
      "Loss: 102.98, 0.00, 26.11 MAE: 1.06, 0.00, 4.72 Decoder scale: 0.97, 0.99 \n",
      "Loss: 102.68, 0.00, 27.37 MAE: 1.03, 0.00, 5.00 Decoder scale: 0.97, 0.99 \n",
      "Loss: 102.69, 0.00, 26.37 MAE: 1.08, 0.00, 4.73 Decoder scale: 0.97, 0.99 \n",
      "Loss: 102.52, 0.00, 26.57 MAE: 1.03, 0.00, 4.84 Decoder scale: 0.97, 0.99 \n",
      "Loss: 102.21, 0.00, 28.34 MAE: 1.00, 0.00, 5.43 Decoder scale: 0.97, 0.99 \n",
      "Loss: 102.23, 0.00, 26.90 MAE: 1.03, 0.00, 4.81 Decoder scale: 0.97, 0.99 \n",
      "Loss: 101.95, 0.00, 26.20 MAE: 0.99, 0.00, 4.71 Decoder scale: 0.97, 0.99 \n",
      "Loss: 102.02, 0.00, 27.69 MAE: 1.04, 0.00, 5.23 Decoder scale: 0.97, 0.99 \n",
      "Loss: 101.74, 0.00, 26.57 MAE: 1.01, 0.00, 4.92 Decoder scale: 0.97, 0.99 \n",
      "Loss: 101.40, 0.00, 26.83 MAE: 0.95, 0.00, 5.02 Decoder scale: 0.97, 0.99 \n",
      "Loss: 101.88, 0.00, 29.37 MAE: 1.06, 0.00, 5.65 Decoder scale: 0.97, 0.99 \n",
      "Loss: 101.50, 0.00, 27.90 MAE: 1.03, 0.00, 5.18 Decoder scale: 0.97, 0.99 \n",
      "Loss: 101.39, 0.00, 26.09 MAE: 1.01, 0.00, 4.85 Decoder scale: 0.97, 0.99 \n",
      "Loss: 101.07, 0.00, 27.09 MAE: 0.97, 0.00, 5.00 Decoder scale: 0.96, 0.99 \n",
      "Loss: 100.93, 0.00, 27.75 MAE: 0.99, 0.00, 5.24 Decoder scale: 0.96, 0.99 \n",
      "Loss: 101.11, 0.00, 29.20 MAE: 1.06, 0.00, 5.53 Decoder scale: 0.96, 0.99 \n",
      "Loss: 100.68, 0.00, 25.91 MAE: 0.99, 0.00, 4.66 Decoder scale: 0.96, 0.99 \n",
      "Loss: 100.70, 0.00, 27.33 MAE: 1.04, 0.00, 5.13 Decoder scale: 0.96, 0.99 \n",
      "Loss: 100.82, 0.00, 25.78 MAE: 1.09, 0.00, 4.58 Decoder scale: 0.96, 0.99 \n",
      "Loss: 100.23, 0.00, 26.35 MAE: 0.96, 0.00, 4.81 Decoder scale: 0.96, 0.99 \n",
      "Loss: 100.06, 0.00, 26.88 MAE: 0.98, 0.00, 4.97 Decoder scale: 0.96, 0.99 \n",
      "Loss: 100.32, 0.00, 25.70 MAE: 1.04, 0.00, 4.94 Decoder scale: 0.96, 0.99 \n",
      "Loss: 99.91, 0.00, 27.17 MAE: 0.98, 0.00, 5.18 Decoder scale: 0.96, 0.99 \n",
      "Loss: 99.62, 0.00, 25.32 MAE: 0.97, 0.00, 4.53 Decoder scale: 0.96, 0.99 \n",
      "Loss: 100.23, 0.00, 27.41 MAE: 1.08, 0.00, 5.13 Decoder scale: 0.96, 0.99 \n",
      "Loss: 99.50, 0.00, 25.16 MAE: 0.97, 0.00, 4.36 Decoder scale: 0.96, 0.99 \n",
      "Loss: 99.28, 0.00, 27.92 MAE: 0.96, 0.00, 5.29 Decoder scale: 0.96, 1.00 \n",
      "Loss: 99.55, 0.00, 27.39 MAE: 1.03, 0.00, 5.28 Decoder scale: 0.96, 1.00 \n",
      "Loss: 99.03, 0.00, 26.02 MAE: 0.97, 0.00, 4.86 Decoder scale: 0.96, 1.00 \n",
      "Loss: 99.19, 0.00, 29.44 MAE: 1.03, 0.00, 5.78 Decoder scale: 0.96, 1.00 \n",
      "Loss: 98.88, 0.00, 26.32 MAE: 0.98, 0.00, 4.88 Decoder scale: 0.96, 1.00 \n",
      "Loss: 98.85, 0.00, 26.42 MAE: 0.99, 0.00, 5.28 Decoder scale: 0.96, 1.00 \n",
      "Loss: 98.87, 0.00, 28.45 MAE: 1.03, 0.00, 5.45 Decoder scale: 0.95, 1.00 \n",
      "Loss: 98.67, 0.00, 27.45 MAE: 1.01, 0.00, 5.11 Decoder scale: 0.95, 1.00 \n",
      "Loss: 98.81, 0.00, 28.59 MAE: 1.05, 0.00, 5.35 Decoder scale: 0.95, 1.00 \n",
      "Loss: 98.55, 0.00, 26.17 MAE: 1.04, 0.00, 4.65 Decoder scale: 0.95, 1.00 \n",
      "Loss: 98.30, 0.00, 25.96 MAE: 1.00, 0.00, 4.83 Decoder scale: 0.95, 1.00 \n",
      "Loss: 98.32, 0.00, 27.99 MAE: 1.04, 0.00, 5.37 Decoder scale: 0.95, 1.00 \n",
      "Loss: 97.99, 0.00, 26.31 MAE: 1.00, 0.00, 4.88 Decoder scale: 0.95, 1.00 \n",
      "Loss: 98.12, 0.00, 27.30 MAE: 1.05, 0.00, 5.05 Decoder scale: 0.95, 1.00 \n",
      "Loss: 98.08, 0.00, 25.94 MAE: 1.07, 0.00, 4.79 Decoder scale: 0.95, 1.00 \n",
      "Loss: 97.69, 0.00, 28.49 MAE: 1.02, 0.00, 5.42 Decoder scale: 0.95, 1.00 \n",
      "Loss: 97.47, 0.00, 26.64 MAE: 1.00, 0.00, 4.94 Decoder scale: 0.95, 1.00 \n",
      "Loss: 98.05, 0.00, 26.84 MAE: 1.12, 0.00, 5.11 Decoder scale: 0.95, 1.00 \n",
      "Loss: 97.16, 0.00, 24.60 MAE: 0.98, 0.00, 4.39 Decoder scale: 0.95, 1.00 \n",
      "Loss: 97.72, 0.00, 28.37 MAE: 1.11, 0.00, 5.60 Decoder scale: 0.95, 1.00 \n",
      "Loss: 97.14, 0.00, 28.21 MAE: 1.01, 0.00, 5.27 Decoder scale: 0.95, 1.00 \n",
      "Loss: 96.78, 0.00, 25.67 MAE: 0.98, 0.00, 4.62 Decoder scale: 0.95, 1.00 \n",
      "Loss: 96.81, 0.00, 26.74 MAE: 1.00, 0.00, 4.92 Decoder scale: 0.95, 1.00 \n",
      "Loss: 96.70, 0.00, 25.95 MAE: 1.01, 0.00, 4.83 Decoder scale: 0.95, 1.00 \n",
      "Loss: 96.34, 0.00, 25.81 MAE: 0.97, 0.00, 4.75 Decoder scale: 0.95, 1.00 \n",
      "Loss: 96.60, 0.00, 28.20 MAE: 1.04, 0.00, 5.43 Decoder scale: 0.95, 1.00 \n",
      "Loss: 96.38, 0.00, 26.77 MAE: 1.02, 0.00, 5.01 Decoder scale: 0.95, 1.00 \n",
      "Loss: 96.68, 0.00, 26.76 MAE: 1.08, 0.00, 5.00 Decoder scale: 0.94, 1.00 \n",
      "Loss: 95.95, 0.00, 27.23 MAE: 0.98, 0.00, 5.03 Decoder scale: 0.94, 1.00 \n",
      "Loss: 96.07, 0.00, 27.58 MAE: 1.03, 0.00, 5.20 Decoder scale: 0.94, 1.00 \n",
      "Loss: 96.19, 0.00, 24.78 MAE: 1.07, 0.00, 4.42 Decoder scale: 0.94, 1.00 \n",
      "Loss: 95.45, 0.00, 28.08 MAE: 0.96, 0.00, 5.46 Decoder scale: 0.94, 1.00 \n",
      "Loss: 95.67, 0.00, 24.84 MAE: 1.05, 0.00, 4.38 Decoder scale: 0.94, 1.00 \n",
      "Loss: 95.68, 0.00, 26.90 MAE: 1.05, 0.00, 5.00 Decoder scale: 0.94, 1.00 \n",
      "Loss: 95.09, 0.00, 27.00 MAE: 0.97, 0.00, 5.09 Decoder scale: 0.94, 1.00 \n",
      "Loss: 95.15, 0.00, 26.31 MAE: 0.98, 0.00, 4.97 Decoder scale: 0.94, 1.00 \n",
      "Loss: 94.92, 0.00, 26.12 MAE: 0.97, 0.00, 4.94 Decoder scale: 0.94, 1.00 \n",
      "Loss: 94.98, 0.00, 25.48 MAE: 1.00, 0.00, 4.66 Decoder scale: 0.94, 1.00 \n",
      "Loss: 95.21, 0.00, 27.25 MAE: 1.09, 0.00, 5.28 Decoder scale: 0.94, 1.00 \n",
      "Loss: 94.41, 0.00, 26.72 MAE: 0.95, 0.00, 4.96 Decoder scale: 0.94, 1.00 \n",
      "Loss: 94.45, 0.00, 25.45 MAE: 0.97, 0.00, 5.01 Decoder scale: 0.94, 1.00 \n",
      "Loss: 94.31, 0.00, 25.89 MAE: 0.98, 0.00, 4.66 Decoder scale: 0.94, 1.00 \n",
      "Loss: 94.19, 0.00, 27.79 MAE: 0.99, 0.00, 5.33 Decoder scale: 0.94, 1.00 \n",
      "Loss: 94.61, 0.00, 27.57 MAE: 1.09, 0.00, 5.19 Decoder scale: 0.94, 1.00 \n",
      "Loss: 94.17, 0.00, 27.05 MAE: 1.00, 0.00, 5.13 Decoder scale: 0.94, 1.00 \n",
      "Loss: 94.22, 0.00, 25.48 MAE: 1.06, 0.00, 4.61 Decoder scale: 0.94, 1.00 \n",
      "Loss: 93.88, 0.00, 23.99 MAE: 1.02, 0.00, 4.26 Decoder scale: 0.94, 1.00 \n",
      "Loss: 93.62, 0.00, 26.66 MAE: 0.99, 0.00, 5.01 Decoder scale: 0.94, 1.00 \n",
      "Loss: 93.50, 0.00, 25.75 MAE: 0.97, 0.00, 5.16 Decoder scale: 0.94, 1.00 \n",
      "Loss: 93.44, 0.00, 25.97 MAE: 1.01, 0.00, 4.92 Decoder scale: 0.94, 1.00 \n",
      "Loss: 93.26, 0.00, 26.58 MAE: 1.00, 0.00, 4.99 Decoder scale: 0.94, 1.00 \n",
      "Loss: 92.82, 0.00, 27.26 MAE: 0.91, 0.00, 5.27 Decoder scale: 0.94, 1.00 \n",
      "Loss: 92.77, 0.00, 25.11 MAE: 0.92, 0.00, 4.66 Decoder scale: 0.94, 1.00 \n",
      "Loss: 93.11, 0.00, 26.39 MAE: 1.03, 0.00, 5.06 Decoder scale: 0.94, 1.00 \n",
      "Loss: 93.05, 0.00, 26.87 MAE: 1.03, 0.00, 5.06 Decoder scale: 0.93, 1.00 \n",
      "Loss: 93.06, 0.00, 27.40 MAE: 1.05, 0.00, 5.29 Decoder scale: 0.93, 1.00 \n",
      "Loss: 92.50, 0.00, 25.50 MAE: 0.99, 0.00, 4.74 Decoder scale: 0.93, 1.00 \n",
      "Loss: 92.19, 0.00, 25.01 MAE: 0.95, 0.00, 4.89 Decoder scale: 0.93, 1.00 \n",
      "Loss: 92.46, 0.00, 25.42 MAE: 1.02, 0.00, 4.64 Decoder scale: 0.93, 1.00 \n",
      "Loss: 92.12, 0.00, 26.68 MAE: 0.99, 0.00, 5.00 Decoder scale: 0.93, 1.00 \n",
      "Loss: 92.10, 0.00, 26.53 MAE: 1.00, 0.00, 5.38 Decoder scale: 0.93, 1.00 \n",
      "Loss: 91.81, 0.00, 26.59 MAE: 0.96, 0.00, 4.96 Decoder scale: 0.93, 1.00 \n",
      "Loss: 91.65, 0.00, 27.57 MAE: 0.97, 0.00, 5.34 Decoder scale: 0.93, 1.00 \n",
      "Loss: 91.80, 0.00, 26.51 MAE: 1.03, 0.00, 4.96 Decoder scale: 0.93, 1.00 \n",
      "Loss: 91.81, 0.00, 26.53 MAE: 1.05, 0.00, 5.18 Decoder scale: 0.93, 1.00 \n",
      "Loss: 91.60, 0.00, 25.65 MAE: 1.04, 0.00, 4.87 Decoder scale: 0.93, 1.00 \n",
      "Loss: 91.35, 0.00, 29.66 MAE: 1.00, 0.00, 5.91 Decoder scale: 0.93, 1.00 \n",
      "Loss: 91.21, 0.00, 24.43 MAE: 0.99, 0.00, 4.39 Decoder scale: 0.93, 1.00 \n",
      "Loss: 91.15, 0.00, 24.69 MAE: 1.01, 0.00, 4.49 Decoder scale: 0.93, 1.00 \n",
      "Loss: 91.42, 0.00, 25.21 MAE: 1.10, 0.00, 4.61 Decoder scale: 0.93, 1.00 \n"
     ]
    }
   ],
   "source": [
    "num_basis_dim = 128\n",
    "\n",
    "covariance = KvvCov(num_basis_dim)\n",
    "add_noise = AddHomoNoise()\n",
    "\n",
    "# covariance = MeanFieldCov(num_basis_dim=1)\n",
    "# add_noise = AddNoNoise()\n",
    "\n",
    "model = EnvResNetConvGNP(covariance=covariance,\n",
    "                         add_noise=add_noise)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(lr=1e-4, params=model.parameters(), weight_decay=1e-3)\n",
    "\n",
    "mae_scale = train_temperature_station_std\n",
    "\n",
    "for i, (train_batch, valid_batch, test_batch) in enumerate(zip(train_data, valid_data, test_data)):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss, mae = model.loss(train_batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            valid_loss, valid_mae = 0, 0 # model.loss(valid_batch)\n",
    "            test_loss, test_mae = model.loss(test_batch)\n",
    "            \n",
    "        decoder_scale = model.decoder.lengthscale.detach().cpu().numpy()\n",
    "            \n",
    "        print(f'Loss: {loss:4.2f}, {valid_loss:4.2f}, {test_loss:4.2f} '\n",
    "              f'MAE: {mae*mae_scale:4.2f}, {valid_mae*mae_scale:4.2f}, {test_mae*mae_scale:4.2f} '\n",
    "              f'Decoder scale: {decoder_scale[0]:.2f}, {decoder_scale[1]:.2f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29583a5-a9f8-4963-80c6-ee1f525c59f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16, 20))\n",
    "# for i in range(80):\n",
    "    \n",
    "#     plt.subplot(10, 8, i+1)\n",
    "#     temp = train_temperature_station[:, i].numpy()\n",
    "#     temp = temp[~np.isnan(temp)]\n",
    "    \n",
    "#     plt.hist(temp)\n",
    "    \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bdca52-d4da-480d-a032-70cbc62fc5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_lonlat_station[:, 0],\n",
    "            train_lonlat_station[:, 1],\n",
    "            zorder=2)\n",
    "\n",
    "plt.scatter(train_lonlat_station[:, 0],\n",
    "            train_lonlat_station[:, 1],\n",
    "            zorder=2)\n",
    "\n",
    "plt.scatter(valid_lonlat_station[:, 0],\n",
    "            valid_lonlat_station[:, 1],\n",
    "            zorder=3)\n",
    "\n",
    "plt.contourf(lonlat_fine[:, :, 0],\n",
    "             lonlat_fine[:, :, 1],\n",
    "             elevation_fine, origin='lower',\n",
    "             alpha=0.5,\n",
    "             cmap='coolwarm',\n",
    "             zorder=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088c85e7-468a-4d48-9213-f58e23d197d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-kernelcnp",
   "language": "python",
   "name": "venv-kernelcnp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
